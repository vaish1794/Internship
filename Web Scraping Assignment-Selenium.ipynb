{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c61caaa7",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc06a5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\vaish\\downloads\\original\\lib\\site-packages (4.4.3)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\vaish\\downloads\\original\\lib\\site-packages (from selenium) (2021.10.8)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\vaish\\downloads\\original\\lib\\site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\users\\vaish\\downloads\\original\\lib\\site-packages (from selenium) (1.26.7)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\vaish\\downloads\\original\\lib\\site-packages (from selenium) (0.21.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\vaish\\downloads\\original\\lib\\site-packages (from trio~=0.17->selenium) (1.14.6)\n",
      "Requirement already satisfied: sniffio in c:\\users\\vaish\\downloads\\original\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: idna in c:\\users\\vaish\\downloads\\original\\lib\\site-packages (from trio~=0.17->selenium) (3.2)\n",
      "Requirement already satisfied: outcome in c:\\users\\vaish\\downloads\\original\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\vaish\\downloads\\original\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\vaish\\downloads\\original\\lib\\site-packages (from trio~=0.17->selenium) (21.2.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\vaish\\downloads\\original\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: pycparser in c:\\users\\vaish\\downloads\\original\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.20)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\vaish\\downloads\\original\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\vaish\\downloads\\original\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\vaish\\downloads\\original\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.13.0)\n",
      "Requirement already satisfied: webdriver-manager in c:\\users\\vaish\\downloads\\original\\lib\\site-packages (3.8.3)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\vaish\\downloads\\original\\lib\\site-packages (from webdriver-manager) (0.21.0)\n",
      "Requirement already satisfied: requests in c:\\users\\vaish\\downloads\\original\\lib\\site-packages (from webdriver-manager) (2.26.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\vaish\\downloads\\original\\lib\\site-packages (from webdriver-manager) (4.62.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vaish\\downloads\\original\\lib\\site-packages (from requests->webdriver-manager) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\vaish\\downloads\\original\\lib\\site-packages (from requests->webdriver-manager) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\vaish\\downloads\\original\\lib\\site-packages (from requests->webdriver-manager) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vaish\\downloads\\original\\lib\\site-packages (from requests->webdriver-manager) (2021.10.8)\n",
      "Requirement already satisfied: colorama in c:\\users\\vaish\\downloads\\original\\lib\\site-packages (from tqdm->webdriver-manager) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "# let's first install the selenium library\n",
    "!pip install selenium\n",
    "!pip install webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b8582d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now import all the required libraries.\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "155e08c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to the driver\n",
    "\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51f261e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the naukri.com website on automated website\n",
    "driver.get(\"https://www.naukri.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3bb5037",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entering designation and location\n",
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys(\"Data Analyst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2cbbe31",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac60be00",
   "metadata": {},
   "outputs": [],
   "source": [
    "clk=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "clk.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dac05a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty lists for scraping\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "786492e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping job title from the given web page\n",
    "title_drive=driver.find_elements(By.XPATH,\"//a[@class='title fw500 ellipsis']\")\n",
    "for i in title_drive[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3f942d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping job location from the given web page\n",
    "location_drive=driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "for i in location_drive[0:10]:\n",
    "    loc1=i.text\n",
    "    job_location.append(loc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ea4a2176",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping Company name \n",
    "com_name=driver.find_elements(By.XPATH,\"//a[@class='subTitle ellipsis fleft']\")\n",
    "for i in com_name[0:10]:\n",
    "    cn=i.text\n",
    "    company_name.append(cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "92c98be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping Job Experience \n",
    "experience_1=driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi experience']\")\n",
    "for i in experience_1[0:10]:\n",
    "    exp=i.text\n",
    "    experience_required.append(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "10fcb0cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(job_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3562ed39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Dataframe\n",
    "data=pd.DataFrame({\"Job Title\":job_title,\"Job Location\":job_location,\"Company Name\":company_name,\"Experience Required\":experience_required})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ad016210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Contractual Hiring For Top MNC || Business Dat...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>TeamLease</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst - Decision Science</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Jana Small Finance Bank</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Associate Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Optum</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Associate Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Optum</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru(Domlur)</td>\n",
       "      <td>KrazyBee</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Novel Office</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Women on career break_ Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Hyderabad/Secunderabad</td>\n",
       "      <td>Zinnov Management C</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BYJU'S DBEL : Sr Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>BYJUS</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SR. Data Analyst- SME- Pharma and Healthcare</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Hyderabad/Secunder...</td>\n",
       "      <td>CHRYSELYS</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Chennai</td>\n",
       "      <td>Botree Software</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0  Contractual Hiring For Top MNC || Business Dat...   \n",
       "1                    Data Analyst - Decision Science   \n",
       "2                             Associate Data Analyst   \n",
       "3                             Associate Data Analyst   \n",
       "4                                Senior Data Analyst   \n",
       "5                                       Data Analyst   \n",
       "6                Women on career break_ Data Analyst   \n",
       "7                      BYJU'S DBEL : Sr Data Analyst   \n",
       "8       SR. Data Analyst- SME- Pharma and Healthcare   \n",
       "9                                       Data Analyst   \n",
       "\n",
       "                                        Job Location             Company Name  \\\n",
       "0                                Bangalore/Bengaluru                TeamLease   \n",
       "1                                Bangalore/Bengaluru  Jana Small Finance Bank   \n",
       "2                                Bangalore/Bengaluru                    Optum   \n",
       "3                                Bangalore/Bengaluru                    Optum   \n",
       "4                        Bangalore/Bengaluru(Domlur)                 KrazyBee   \n",
       "5                                Bangalore/Bengaluru             Novel Office   \n",
       "6        Bangalore/Bengaluru, Hyderabad/Secunderabad      Zinnov Management C   \n",
       "7                                Bangalore/Bengaluru                    BYJUS   \n",
       "8  Bangalore/Bengaluru, Noida, Hyderabad/Secunder...                CHRYSELYS   \n",
       "9                       Bangalore/Bengaluru, Chennai          Botree Software   \n",
       "\n",
       "  Experience Required  \n",
       "0             5-8 Yrs  \n",
       "1             3-8 Yrs  \n",
       "2             2-7 Yrs  \n",
       "3             1-4 Yrs  \n",
       "4             3-5 Yrs  \n",
       "5             0-3 Yrs  \n",
       "6            5-10 Yrs  \n",
       "7             3-7 Yrs  \n",
       "8             2-6 Yrs  \n",
       "9             1-5 Yrs  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d46ffa5",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2739693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Job Opportunity on Data Science_ Python with T...</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...</td>\n",
       "      <td>Tech Mahindra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Assistant Manager - Data Science</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Pune</td>\n",
       "      <td>CitiusTech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Analystics &amp; Modeling Specialist</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hiring For DATA Scientist @ NTT DATA Business ...</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Hyderabad/Secunder...</td>\n",
       "      <td>NTT DATA Business Solutions Private Limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist/AIML Engineer</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...</td>\n",
       "      <td>upGrad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ACN - Applied Intelligence - C4DI - Sustainabi...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lead ML Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tcs Hiring For Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Chennai, Mumbai (All Areas)</td>\n",
       "      <td>TATA CONSULTANCY SERVICES (TCS)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist - II</td>\n",
       "      <td>Bangalore/Bengaluru, India, Mumbai (All Areas)</td>\n",
       "      <td>SMARTPADDLE TECHNOLOGY PVT. LTD.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist - A.P. Maersk</td>\n",
       "      <td>Bangalore/Bengaluru\\n(WFH during Covid)</td>\n",
       "      <td>Maersk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0  Job Opportunity on Data Science_ Python with T...   \n",
       "1                   Assistant Manager - Data Science   \n",
       "2                   Analystics & Modeling Specialist   \n",
       "3  Hiring For DATA Scientist @ NTT DATA Business ...   \n",
       "4                       Data Scientist/AIML Engineer   \n",
       "5  ACN - Applied Intelligence - C4DI - Sustainabi...   \n",
       "6                                  Lead ML Scientist   \n",
       "7                      Tcs Hiring For Data Scientist   \n",
       "8                                Data Scientist - II   \n",
       "9                       Data Scientist - A.P. Maersk   \n",
       "\n",
       "                                        Job Location  \\\n",
       "0  Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...   \n",
       "1                  Bangalore/Bengaluru, Mumbai, Pune   \n",
       "2  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...   \n",
       "3  Bangalore/Bengaluru, Noida, Hyderabad/Secunder...   \n",
       "4  Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6                        Bangalore/Bengaluru, Mumbai   \n",
       "7   Bangalore/Bengaluru, Chennai, Mumbai (All Areas)   \n",
       "8     Bangalore/Bengaluru, India, Mumbai (All Areas)   \n",
       "9            Bangalore/Bengaluru\\n(WFH during Covid)   \n",
       "\n",
       "                                  Company Name  \n",
       "0                                Tech Mahindra  \n",
       "1                                   CitiusTech  \n",
       "2                                    Accenture  \n",
       "3  NTT DATA Business Solutions Private Limited  \n",
       "4                                       upGrad  \n",
       "5                                    Accenture  \n",
       "6                            Fractal Analytics  \n",
       "7              TATA CONSULTANCY SERVICES (TCS)  \n",
       "8             SMARTPADDLE TECHNOLOGY PVT. LTD.  \n",
       "9                                       Maersk  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's now import all the required libraries.\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "#Connecting to the driver\n",
    "\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "#Opening the naukri.com website on automated website\n",
    "driver.get(\"https://www.naukri.com\")\n",
    "\n",
    "#Entering designation and location\n",
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys(\"Data Scientist\")\n",
    "\n",
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys(\"Bangalore\")\n",
    "\n",
    "clk=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "clk.click()\n",
    "\n",
    "#Creating empty lists for scraping\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "\n",
    "#Scraping job title from the given web page\n",
    "title_drive=driver.find_elements(By.XPATH,\"//a[@class='title fw500 ellipsis']\")\n",
    "for i in title_drive[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "\n",
    "#Scraping job location from the given web page\n",
    "location_drive=driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "for i in location_drive[0:10]:\n",
    "    loc1=i.text\n",
    "    job_location.append(loc1)\n",
    "\n",
    "#Scraping Company name \n",
    "com_name=driver.find_elements(By.XPATH,\"//a[@class='subTitle ellipsis fleft']\")\n",
    "for i in com_name[0:10]:\n",
    "    cn=i.text\n",
    "    company_name.append(cn)\n",
    "\n",
    "#Creating Dataframe\n",
    "data=pd.DataFrame({\"Job Title\":job_title,\"Job Location\":job_location,\"Company Name\":company_name})\n",
    "data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402d9aaf",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37b82af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now import all the required libraries.\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "\n",
    "#Creating empty lists for scraping\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b928447f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to the driver\n",
    "\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac269c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the naukri.com website on automated website\n",
    "driver.get(\"https://www.naukri.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62c66a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entering designation \n",
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys(\"Data Scientist\")\n",
    "clk=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "clk.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68972207",
   "metadata": {},
   "outputs": [],
   "source": [
    "clk1=driver.find_element(By.XPATH,\"/html/body/div[1]/div[4]/div/section[1]/div[2]/div[5]/div[2]/div[3]/label/i\")\n",
    "clk1.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f6e90ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "clk2=driver.find_element(By.XPATH,\"/html/body/div[1]/div[4]/div/section[1]/div[2]/div[6]/div[2]/div[2]/label/i\")\n",
    "clk2.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb7f0a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty lists for scraping\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac4ddf19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida, Nagpur, Bangalore/Bengaluru</td>\n",
       "      <td>GlobalLogic</td>\n",
       "      <td>8-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DigitalBCG GAMMA Data Scientist</td>\n",
       "      <td>New Delhi, Bangalore/Bengaluru</td>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Optum</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist / Chat-bot Developer</td>\n",
       "      <td>New Delhi, Bangalore/Bengaluru, Mumbai (All Ar...</td>\n",
       "      <td>Big Seo Buzz</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Noida(Sector-59 Noida)\\n(WFH during Covid)</td>\n",
       "      <td>R Systems International</td>\n",
       "      <td>7-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist - Predictive Analytics</td>\n",
       "      <td>Noida, Mumbai, Chandigarh, Hyderabad/Secundera...</td>\n",
       "      <td>Confidential</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Knowledge/Data Scientist</td>\n",
       "      <td>Delhi / NCR</td>\n",
       "      <td>BOLD Technology Systems</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Feedback Infra</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>4i Odc</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist, Associate</td>\n",
       "      <td>Delhi / NCR</td>\n",
       "      <td>NatWest Group</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Job Title  \\\n",
       "0                         Data Scientist   \n",
       "1        DigitalBCG GAMMA Data Scientist   \n",
       "2                         Data Scientist   \n",
       "3    Data Scientist / Chat-bot Developer   \n",
       "4                    Lead Data Scientist   \n",
       "5  Data Scientist - Predictive Analytics   \n",
       "6               Knowledge/Data Scientist   \n",
       "7                         Data Scientist   \n",
       "8                         Data Scientist   \n",
       "9              Data Scientist, Associate   \n",
       "\n",
       "                                        Job Location             Company Name  \\\n",
       "0                 Noida, Nagpur, Bangalore/Bengaluru              GlobalLogic   \n",
       "1                     New Delhi, Bangalore/Bengaluru  Boston Consulting Group   \n",
       "2                                   Gurgaon/Gurugram                    Optum   \n",
       "3  New Delhi, Bangalore/Bengaluru, Mumbai (All Ar...             Big Seo Buzz   \n",
       "4         Noida(Sector-59 Noida)\\n(WFH during Covid)  R Systems International   \n",
       "5  Noida, Mumbai, Chandigarh, Hyderabad/Secundera...             Confidential   \n",
       "6                                        Delhi / NCR  BOLD Technology Systems   \n",
       "7                                   Gurgaon/Gurugram           Feedback Infra   \n",
       "8                                              Noida                   4i Odc   \n",
       "9                                        Delhi / NCR            NatWest Group   \n",
       "\n",
       "  Experience Required  \n",
       "0            8-10 Yrs  \n",
       "1             2-5 Yrs  \n",
       "2             2-7 Yrs  \n",
       "3             3-7 Yrs  \n",
       "4            7-10 Yrs  \n",
       "5             1-6 Yrs  \n",
       "6             3-6 Yrs  \n",
       "7             2-4 Yrs  \n",
       "8             2-4 Yrs  \n",
       "9             2-7 Yrs  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Scraping job title from the given web page\n",
    "title_drive=driver.find_elements(By.XPATH,\"//a[@class='title fw500 ellipsis']\")\n",
    "for i in title_drive[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "\n",
    "#Scraping job location from the given web page\n",
    "location_drive=driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "for i in location_drive[0:10]:\n",
    "    loc1=i.text\n",
    "    job_location.append(loc1)\n",
    "\n",
    "#Scraping Company name \n",
    "com_name=driver.find_elements(By.XPATH,\"//a[@class='subTitle ellipsis fleft']\")\n",
    "for i in com_name[0:10]:\n",
    "    cn=i.text\n",
    "    company_name.append(cn)\n",
    "\n",
    "#Scraping Job Experience \n",
    "experience_1=driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi experience']\")\n",
    "for i in experience_1[0:10]:\n",
    "    exp=i.text\n",
    "    experience_required.append(exp)\n",
    "\n",
    "#Creating Dataframe\n",
    "data=pd.DataFrame({\"Job Title\":job_title,\"Job Location\":job_location,\"Company Name\":company_name,\"Experience Required\":experience_required})\n",
    "data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ba7c5c",
   "metadata": {},
   "source": [
    "# Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "09ae15e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now import all the required libraries.\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "from time import sleep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eb22316d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to the driver\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "06244740",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the Flipkart website on automated website\n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "27dc168f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entering Sunglasses in the search field\n",
    "prod=driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "prod.send_keys(\"Sunglasses\")\n",
    "clk=driver.find_element(By.CLASS_NAME,\"L0Z3Pu\")\n",
    "clk.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2778bfb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1\n",
      "Scraping page 2\n",
      "Scraping page 3\n"
     ]
    }
   ],
   "source": [
    "products=[]\n",
    "des=[]\n",
    "price=[]\n",
    "for i in range(3):\n",
    "    print ('Scraping page',i+1)\n",
    "    product_brand=driver.find_elements(By.XPATH,\"//div[@class='_2WkVRV']\")\n",
    "    for p in product_brand:\n",
    "        products.append (p.text)\n",
    "    product_des=driver.find_elements(By.XPATH,\"//a[@class='IRpwTa']\")\n",
    "    for d in product_des:\n",
    "        des.append(d.text)\n",
    "    product_price=driver.find_elements(By.XPATH,\"//div[@class='_30jeq3']\")\n",
    "    for pr in product_price:\n",
    "        price.append(pr.text)\n",
    "    next_button = driver.find_element(By.CLASS_NAME,\"_1LKTO3\")\n",
    "    next_button.click()\n",
    "    sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2c8f1eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Retro Squ...</td>\n",
       "      <td>₹901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (Free Size)</td>\n",
       "      <td>₹449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AISLIN</td>\n",
       "      <td>UV Protection, Gradient Butterfly, Retro Squar...</td>\n",
       "      <td>₹415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection, Gradient Rectangular Sunglasses...</td>\n",
       "      <td>₹319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>UV Protection, Gradient Oval Sunglasses (60)</td>\n",
       "      <td>₹479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Mi</td>\n",
       "      <td>Polarized Rectangular Sunglasses (60)</td>\n",
       "      <td>₹799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>AISLIN</td>\n",
       "      <td>by Lenskart UV Protection Round Sunglasses (58)</td>\n",
       "      <td>₹448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>Polarized, UV Protection Wayfarer, Retro Squar...</td>\n",
       "      <td>₹559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>UV Protection Over-sized Sunglasses (65)</td>\n",
       "      <td>₹1,049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand                                        Description   Price\n",
       "0         Fastrack      UV Protection Wayfarer Sunglasses (Free Size)    ₹799\n",
       "1    VINCENT CHASE  by Lenskart Polarized, UV Protection Retro Squ...    ₹901\n",
       "2   ROZZETTA CRAFT  UV Protection Retro Square Sunglasses (Free Size)    ₹449\n",
       "3           AISLIN  UV Protection, Gradient Butterfly, Retro Squar...    ₹415\n",
       "4   ROZZETTA CRAFT  UV Protection, Gradient Rectangular Sunglasses...    ₹319\n",
       "..             ...                                                ...     ...\n",
       "95       ROYAL SON       UV Protection, Gradient Oval Sunglasses (60)    ₹479\n",
       "96              Mi              Polarized Rectangular Sunglasses (60)    ₹799\n",
       "97          AISLIN    by Lenskart UV Protection Round Sunglasses (58)    ₹448\n",
       "98       ROYAL SON  Polarized, UV Protection Wayfarer, Retro Squar...    ₹559\n",
       "99   VINCENT CHASE           UV Protection Over-sized Sunglasses (65)  ₹1,049\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe\n",
    "lists = [products[0:100],des[0:100],price[0:100]]\n",
    "flipkart_sunglasses = pd.concat([pd.Series(x) for x in lists], axis=1)\n",
    "flipkart_sunglasses.columns=[\"Brand\",\"Description\",\"Price\"]\n",
    "flipkart_sunglasses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d437a3f2",
   "metadata": {},
   "source": [
    "# Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "46c30a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now import all the required libraries.\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "from time import sleep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "04b63687",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to the driver\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9256bbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the naukri.com website on automated website\n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c19870f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entering i phone 11 in the search field\n",
    "prod=driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "prod.send_keys(\"i phone 11\")\n",
    "clk=driver.find_element(By.CLASS_NAME,\"L0Z3Pu\")\n",
    "clk.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "151eaa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting i phone 11 url from the list\n",
    "temp=driver.find_element(By.XPATH,\"//a[@class='_1fQZEK']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "038fc09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the url\n",
    "driver.get(temp.get_attribute(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3d1a3e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting Reviews Section\n",
    "\n",
    "clk1=driver.find_element(By.XPATH,\"//span[@class='_2_R_DZ']\")\n",
    "clk1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e6d30192",
   "metadata": {},
   "outputs": [],
   "source": [
    "clk2=driver.find_element(By.XPATH,\"//div[@class='_3UAT2v _16PBlm']\")\n",
    "clk2.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8fa94ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty lists for reviews\n",
    "rating=[]\n",
    "review_summary=[]\n",
    "full_review=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b2a2000f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1\n",
      "Scraping page 2\n",
      "Scraping page 3\n",
      "Scraping page 4\n",
      "Scraping page 5\n",
      "Scraping page 6\n",
      "Scraping page 7\n",
      "Scraping page 8\n",
      "Scraping page 9\n",
      "Scraping page 10\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print ('Scraping page',i+1)\n",
    "    rate=driver.find_elements(By.XPATH,\"//div[@class='_3LWZlK _1BLPMq']\")\n",
    "    for p in rate:\n",
    "        rating.append (p.text)\n",
    "    rev=driver.find_elements(By.XPATH,\"//p[@class='_2-N8zT']\")\n",
    "    for d in rev:\n",
    "        review_summary.append(d.text)\n",
    "    fullrev=driver.find_elements(By.XPATH,\"//div[@class='t-ZTKy']\")\n",
    "    for pr in fullrev:\n",
    "        full_review.append(pr.text)\n",
    "    next_button = driver.find_element(By.CLASS_NAME,\"_1LKTO3\")\n",
    "    next_button.click()\n",
    "    sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "54e2fd2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review Summary</th>\n",
       "      <th>Full Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>What a camera .....just awesome ..you can feel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Smooth like butter, camera like fantabulous, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>Amazing camera quality as expected, battery al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Iphone is just awesome.. battery backup is ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific</td>\n",
       "      <td>Really worth of money. i just love it. It is t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>This is my first ever I phone. Before this I w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating       Review Summary  \\\n",
       "0       5       Simply awesome   \n",
       "1       5     Perfect product!   \n",
       "2       5  Best in the market!   \n",
       "3       5   Highly recommended   \n",
       "4       5    Worth every penny   \n",
       "..    ...                  ...   \n",
       "95      5    Worth every penny   \n",
       "96      5   Highly recommended   \n",
       "97      5     Perfect product!   \n",
       "98      5             Terrific   \n",
       "99      5            Wonderful   \n",
       "\n",
       "                                          Full Review  \n",
       "0   Really satisfied with the Product I received.....  \n",
       "1   Amazing phone with great cameras and better ba...  \n",
       "2   Great iPhone very snappy experience as apple k...  \n",
       "3   What a camera .....just awesome ..you can feel...  \n",
       "4   Previously I was using one plus 3t it was a gr...  \n",
       "..                                                ...  \n",
       "95  Smooth like butter, camera like fantabulous, s...  \n",
       "96  Amazing camera quality as expected, battery al...  \n",
       "97  Iphone is just awesome.. battery backup is ver...  \n",
       "98  Really worth of money. i just love it. It is t...  \n",
       "99  This is my first ever I phone. Before this I w...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe\n",
    "lists = [rating,review_summary,full_review]\n",
    "flipkart_iphone11= pd.concat([pd.Series(x) for x in lists], axis=1)\n",
    "flipkart_iphone11.columns=[\"Rating\",\"Review Summary\",\"Full Review\"]\n",
    "flipkart_iphone11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fce53bf",
   "metadata": {},
   "source": [
    "# Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "69eff023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now import all the required libraries.\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "af6e6c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to the driver\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d55aa7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the naukri.com website on automated website\n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9e8fa061",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entering i phone 11 in the search field\n",
    "prod=driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "prod.send_keys(\"sneakers\")\n",
    "clk=driver.find_element(By.CLASS_NAME,\"L0Z3Pu\")\n",
    "clk.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8a73c867",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty lists\n",
    "brand=[]\n",
    "product_des=[]\n",
    "price=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2c73bd30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1\n",
      "Scraping page 2\n",
      "Scraping page 3\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print ('Scraping page',i+1)\n",
    "    product_brand=driver.find_elements(By.XPATH,\"//div[@class='_2WkVRV']\")\n",
    "    for p in product_brand:\n",
    "        brand.append (p.text)\n",
    "    des=driver.find_elements(By.XPATH,\"//a[@class='IRpwTa']\")\n",
    "    for d in des:\n",
    "        product_des.append(d.text)\n",
    "    product_price=driver.find_elements(By.XPATH,\"//div[@class='_30jeq3']\")\n",
    "    for pr in product_price:\n",
    "        price.append(pr.text)\n",
    "    next_button = driver.find_element(By.CLASS_NAME,\"_1LKTO3\")\n",
    "    next_button.click()\n",
    "    sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b7c25b17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Labbin</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TR</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Shozie</td>\n",
       "      <td>Breathable, Walking, Running, Casual, Gym Shoe...</td>\n",
       "      <td>₹379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kraasa</td>\n",
       "      <td>Casuals, Canvas, Partywear Sneakers For Men</td>\n",
       "      <td>₹428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Layasa</td>\n",
       "      <td>supr Sneakers For Men</td>\n",
       "      <td>₹199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Layasa</td>\n",
       "      <td>Modern Trendy Sneakers boot Sneakers For Men</td>\n",
       "      <td>₹199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Sneakers For Women</td>\n",
       "      <td>₹407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>RapidBox</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Kzaara</td>\n",
       "      <td>Lattest Sneakers Shoe Sneakers For Men</td>\n",
       "      <td>₹233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>HOTSTYLE</td>\n",
       "      <td>sneaker men red 1258 - 10 Sneakers For Men</td>\n",
       "      <td>₹292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Brand                                        Description Price\n",
       "0     Labbin                                   Sneakers For Men  ₹399\n",
       "1         TR                                   Sneakers For Men  ₹295\n",
       "2     Shozie  Breathable, Walking, Running, Casual, Gym Shoe...  ₹379\n",
       "3     Kraasa        Casuals, Canvas, Partywear Sneakers For Men  ₹428\n",
       "4     Layasa                              supr Sneakers For Men  ₹199\n",
       "..       ...                                                ...   ...\n",
       "95    Layasa       Modern Trendy Sneakers boot Sneakers For Men  ₹199\n",
       "96    Chevit                                 Sneakers For Women  ₹407\n",
       "97  RapidBox                                   Sneakers For Men  ₹549\n",
       "98    Kzaara             Lattest Sneakers Shoe Sneakers For Men  ₹233\n",
       "99  HOTSTYLE         sneaker men red 1258 - 10 Sneakers For Men  ₹292\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe\n",
    "lists = [brand[0:100],product_des[0:100],price[0:100]]\n",
    "flipkart_sneakers = pd.concat([pd.Series(x) for x in lists], axis=1)\n",
    "flipkart_sneakers.columns=[\"Brand\",\"Description\",\"Price\"]\n",
    "flipkart_sneakers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c2095f",
   "metadata": {},
   "source": [
    "# Question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "81ed93cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b76cfb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to the driver\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "59fa121f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the Myntra website on automated website\n",
    "driver.get(\"https://www.myntra.com/shoes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dd740452",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying the price and color filter\n",
    "color=driver.find_element(By.XPATH,\"/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]/label/div\")\n",
    "color.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4dfe3664",
   "metadata": {},
   "outputs": [],
   "source": [
    "price=driver.find_element(By.XPATH,\"/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label/div\")\n",
    "price.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7fbe51b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty lists\n",
    "brand=[]\n",
    "product_des=[]\n",
    "price=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a3ba4ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1\n",
      "Scraping page 2\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    print ('Scraping page',i+1)\n",
    "    product_brand=driver.find_elements(By.XPATH,\"//h3[@class='product-brand']\")\n",
    "    for p in product_brand:\n",
    "        brand.append (p.text)\n",
    "    des=driver.find_elements(By.XPATH,\"//h4[@class='product-product']\")\n",
    "    for d in des:\n",
    "        product_des.append(d.text)\n",
    "    product_price=driver.find_elements(By.XPATH,\"//div[@class='product-price']\")\n",
    "    for pr in product_price:\n",
    "        price.append(pr.text)\n",
    "    next_button = driver.find_element(By.CLASS_NAME,\"pagination-next\")\n",
    "    next_button.click()\n",
    "    sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c0c0777d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADIDAS Originals</td>\n",
       "      <td>Men Niteball II Sneakers</td>\n",
       "      <td>Rs. 9349Rs. 10999(15% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men ZOOM WINFLO8 Running Shoes</td>\n",
       "      <td>Rs. 7880Rs. 8295(5% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men React Infinity 3 Running</td>\n",
       "      <td>Rs. 13295Rs. 13995(5% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADIDAS Originals</td>\n",
       "      <td>Men Leather Niteball Sneakers</td>\n",
       "      <td>Rs. 10799Rs. 11999(10% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Eternity Nitro Running Shoes</td>\n",
       "      <td>Rs. 12999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Tommy Hilfiger</td>\n",
       "      <td>Women Leather Sneakers</td>\n",
       "      <td>Rs. 8599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Skechers</td>\n",
       "      <td>Women Arch Fit Slip-On Sneaker</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Tommy Hilfiger</td>\n",
       "      <td>Women Leather Kitten Sandals</td>\n",
       "      <td>Rs. 7199Rs. 7999(10% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Columbia</td>\n",
       "      <td>Women REDMOND V2 TrekkingShoe</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ADIDAS</td>\n",
       "      <td>Women Solar Glide 5 Running</td>\n",
       "      <td>Rs. 9799Rs. 13999(30% OFF)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Brand                     Description  \\\n",
       "0   ADIDAS Originals        Men Niteball II Sneakers   \n",
       "1               Nike  Men ZOOM WINFLO8 Running Shoes   \n",
       "2               Nike    Men React Infinity 3 Running   \n",
       "3   ADIDAS Originals   Men Leather Niteball Sneakers   \n",
       "4               Puma    Eternity Nitro Running Shoes   \n",
       "..               ...                             ...   \n",
       "95    Tommy Hilfiger          Women Leather Sneakers   \n",
       "96          Skechers  Women Arch Fit Slip-On Sneaker   \n",
       "97    Tommy Hilfiger    Women Leather Kitten Sandals   \n",
       "98          Columbia   Women REDMOND V2 TrekkingShoe   \n",
       "99            ADIDAS     Women Solar Glide 5 Running   \n",
       "\n",
       "                          Price  \n",
       "0    Rs. 9349Rs. 10999(15% OFF)  \n",
       "1      Rs. 7880Rs. 8295(5% OFF)  \n",
       "2    Rs. 13295Rs. 13995(5% OFF)  \n",
       "3   Rs. 10799Rs. 11999(10% OFF)  \n",
       "4                     Rs. 12999  \n",
       "..                          ...  \n",
       "95                     Rs. 8599  \n",
       "96                     Rs. 7999  \n",
       "97    Rs. 7199Rs. 7999(10% OFF)  \n",
       "98                     Rs. 7999  \n",
       "99   Rs. 9799Rs. 13999(30% OFF)  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe\n",
    "lists = [brand,product_des,price]\n",
    "myntra_shoes=pd.concat([pd.Series(x) for x in lists], axis=1)\n",
    "myntra_shoes.columns=[\"Brand\",\"Description\",\"Price\"]\n",
    "myntra_shoes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8a9114",
   "metadata": {},
   "source": [
    "# Question 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8273ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "from time import sleep\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4f3248",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to the driver\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcefbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the Amazon website on automated website\n",
    "driver.get(\"https://www.amazon.in/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5101b4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entering \"Laptop\" in search field\n",
    "item=driver.find_element(By.XPATH,\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input\")\n",
    "item.send_keys(\"Laptop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a497c4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH,\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div/span/input\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7416bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying CPU Type filter\n",
    "cpu_filter=driver.find_element(By.XPATH,\"//*[@id='p_n_feature_thirteen_browse-bin/12598163031']/span/a\")\n",
    "cpu_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d18ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty lists\n",
    "title=[]\n",
    "rating=[]\n",
    "price=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40fd4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping laptop title\n",
    "a=driver.find_elements(By.XPATH,\"//h2[@class='a-size-mini a-spacing-none a-color-base s-line-clamp-2']\")\n",
    "for i1 in a:\n",
    "    title.append(i1.text)\n",
    "      \n",
    "#Scraping Laptop Price\n",
    "c=driver.find_elements(By.CLASS_NAME,\"a-price-whole\")\n",
    "for i3 in c:\n",
    "    price.append(i3.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c32144",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping Laptop Rating\n",
    "b=driver.find_element(By.XPATH,\"//i[@class='a-icon a-icon-star-small a-star-small-4-5 aok-align-bottom']\")\n",
    "b.click()\n",
    "b1=driver.find_elements(By.XPATH,\"//span[@class='a-size-medium a-color-base a-text-beside-button a-text-bold']\")\n",
    "for i2 in b1:\n",
    "    rating.append(i2.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df97e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dataframe\n",
    "lists = [title,price,rating]\n",
    "amazon=pd.concat([pd.Series(x) for x in lists], axis=1)\n",
    "amazon.columns=[\"Laptop Title\",\"Price\",\"Rating\"]\n",
    "amazon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727d4030",
   "metadata": {},
   "source": [
    "# Question 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf53197d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now import all the required libraries.\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00423b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to the driver\n",
    "\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a888ab2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the website on automated website\n",
    "driver.get(\"https://www.ambitionbox.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "265f1ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting job section\n",
    "job=driver.find_element(By.CLASS_NAME,\"navItemLink\")\n",
    "job.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "baa87955",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entering the job designation-Data Scientist\n",
    "job_designation=driver.find_element(By.XPATH,\"//*[@id='jobs-typeahead']/span/input\")\n",
    "job_designation.send_keys(\"Data Scientist\")\n",
    "search=driver.find_element(By.CLASS_NAME,\"ctas-btn-medium\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "36607aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying Noida as location filter\n",
    "locate_search=driver.find_element(By.XPATH,\"/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[1]/i\")\n",
    "lock=driver.find_element(By.XPATH,\"/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[2]/input\")\n",
    "\n",
    "lock.send_keys(\"Noida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1188be77",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel=driver.find_element(By.XPATH,\"/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[3]/div[1]/div[1]/div/input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "40850f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aabd63a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty lists for scraping\n",
    "company=[]\n",
    "days=[]\n",
    "rating=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "47c9710b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=driver.find_elements(By.XPATH,\"//p[@class='company body-medium']\")\n",
    "for i in a:\n",
    "    company.append(i.text)\n",
    "    \n",
    "b=driver.find_elements(By.XPATH,\"//span[@class='body-small-l']\")\n",
    "for i1 in b:\n",
    "    days.append(i1.text)\n",
    "    \n",
    "days_ago=days[0::2]\n",
    "days_ago\n",
    "\n",
    "c=driver.find_elements(By.XPATH,\"//span[@class='body-small']\")\n",
    "for i2 in c:\n",
    "    rating.append(i2.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b91810af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>No. of days ago when job was posted</th>\n",
       "      <th>Rating of the company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Optum Global Solutions (India) Private Limited</td>\n",
       "      <td>6d ago</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BARCLAYS GLOBAL SERVICE CENTRE PRIVATE LIMITED</td>\n",
       "      <td>4d ago</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EY GDS</td>\n",
       "      <td>6d ago</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GLOBALLOGIC INDIA PRIVATE LIMITED</td>\n",
       "      <td>4d ago</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GENPACT India Private Limited</td>\n",
       "      <td>26d ago</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Genpact</td>\n",
       "      <td>28d ago</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ericsson India Global Services Pvt. Ltd.</td>\n",
       "      <td>1mon ago</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dew Solutions Pvt. Ltd.</td>\n",
       "      <td>11d ago</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>One97 Communications Limited</td>\n",
       "      <td>19d ago</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EY</td>\n",
       "      <td>1mon ago</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Company  \\\n",
       "0  Optum Global Solutions (India) Private Limited   \n",
       "1  BARCLAYS GLOBAL SERVICE CENTRE PRIVATE LIMITED   \n",
       "2                                          EY GDS   \n",
       "3               GLOBALLOGIC INDIA PRIVATE LIMITED   \n",
       "4                   GENPACT India Private Limited   \n",
       "5                                         Genpact   \n",
       "6        Ericsson India Global Services Pvt. Ltd.   \n",
       "7                         Dew Solutions Pvt. Ltd.   \n",
       "8                    One97 Communications Limited   \n",
       "9                                              EY   \n",
       "\n",
       "   No. of days ago when job was posted Rating of the company  \n",
       "0                               6d ago                   4.1  \n",
       "1                               4d ago                   4.3  \n",
       "2                               6d ago                   3.8  \n",
       "3                               4d ago                   4.0  \n",
       "4                              26d ago                   4.0  \n",
       "5                              28d ago                   4.0  \n",
       "6                             1mon ago                   4.3  \n",
       "7                              11d ago                   4.3  \n",
       "8                              19d ago                   3.8  \n",
       "9                             1mon ago                   3.8  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe\n",
    "lists = [company,days_ago,rating]\n",
    "ambition=pd.concat([pd.Series(x) for x in lists], axis=1)\n",
    "ambition.columns=[\"Company\",\" No. of days ago when job was posted\",\"Rating of the company\"]\n",
    "ambition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56eedf9",
   "metadata": {},
   "source": [
    "# Question 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3d895df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now import all the required libraries.\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import numpy as np\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b2580f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to the driver\n",
    "\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bc7c0235",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the website on automated website\n",
    "driver.get(\"https://www.ambitionbox.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1bee3a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on the salary option\n",
    "sal=driver.find_element(By.XPATH,\"//*[@id='ambitionbox-header']/nav/ul/li[3]/span\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "87b393a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt=driver.find_element(By.XPATH,\"/html/body/div/div/div/div[1]/header/nav/ul/li[3]/div/ul/li[1]/div/div[2]/a\")\n",
    "driver.get(opt.get_attribute(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5cba2b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entering Data Scientist\n",
    "\n",
    "role=driver.find_element(By.XPATH,\"/html/body/div/div/div/main/section[1]/div[2]/div[1]/span/input\")\n",
    "                                  \n",
    "role.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7bcfafa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "var1=driver.find_element(By.XPATH,\"/html/body/div/div/div/main/section[1]/div[2]/div[1]/span/input\")\n",
    "var1.click()\n",
    "\n",
    "var2=driver.find_element(By.XPATH,\"/html/body/div/div/div/main/section[1]/div[2]/div[1]/span/div/div/div[1]\")\n",
    "var2.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d9e85ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty lists\n",
    "company=[]\n",
    "average_salary=[]\n",
    "min_sal=[]\n",
    "max_sal=[]\n",
    "sam=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6ad2c10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping company name,salary record, years of experience\n",
    "n1=driver.find_elements(By.XPATH,\"//div[@class='company-info']\")\n",
    "for i2 in n1:\n",
    "    company.append(i2.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ed52326f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping Average Salary\n",
    "c=driver.find_elements(By.XPATH,\"//p[@class='averageCtc']\")\n",
    "for i in c:\n",
    "    average_salary.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4f32cf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping min and max salary\n",
    "d=driver.find_elements(By.XPATH,\"//div[@class='value body-medium']\")\n",
    "for i1 in d:\n",
    "    sam.append(i1.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5b4c92a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sal=sam[0::2]\n",
    "max_sal=sam[1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2ad0d23c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Average Salary</th>\n",
       "      <th>Minimum Salary</th>\n",
       "      <th>Maximum Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Walmart\\nData Scientist Salary\\n3-4 yrs experi...</td>\n",
       "      <td>₹ 32.3L</td>\n",
       "      <td>₹ 25.0L</td>\n",
       "      <td>₹ 45.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ab Inbev\\nData Scientist Salary\\n2-4 yrs exper...</td>\n",
       "      <td>₹ 19.9L</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "      <td>₹ 26.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Optum\\nData Scientist Salary\\n2-4 yrs experien...</td>\n",
       "      <td>₹ 16.4L</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 22.6L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZS\\nData Scientist Salary\\n1-2 yrs experience ...</td>\n",
       "      <td>₹ 15.8L</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 22.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fractal Analytics\\nData Scientist Salary\\n2-4 ...</td>\n",
       "      <td>₹ 15.4L</td>\n",
       "      <td>₹ 9.0L</td>\n",
       "      <td>₹ 23.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tiger Analytics\\nData Scientist Salary\\n2-4 yr...</td>\n",
       "      <td>₹ 14.7L</td>\n",
       "      <td>₹ 9.0L</td>\n",
       "      <td>₹ 20.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sigmoid Analytics\\nData Scientist Salary\\n1 yr...</td>\n",
       "      <td>₹ 14.7L</td>\n",
       "      <td>₹ 12.7L</td>\n",
       "      <td>₹ 19.7L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Legato Health Technologies\\nData Scientist Sal...</td>\n",
       "      <td>₹ 14.5L</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 20.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HSBC\\nData Scientist Salary\\n4 yrs experience ...</td>\n",
       "      <td>₹ 14.0L</td>\n",
       "      <td>₹ 12.0L</td>\n",
       "      <td>₹ 18.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tredence\\nData Scientist Salary\\n3 yrs experie...</td>\n",
       "      <td>₹ 13.9L</td>\n",
       "      <td>₹ 8.8L</td>\n",
       "      <td>₹ 17.5L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Company Average Salary  \\\n",
       "0  Walmart\\nData Scientist Salary\\n3-4 yrs experi...        ₹ 32.3L   \n",
       "1  Ab Inbev\\nData Scientist Salary\\n2-4 yrs exper...        ₹ 19.9L   \n",
       "2  Optum\\nData Scientist Salary\\n2-4 yrs experien...        ₹ 16.4L   \n",
       "3  ZS\\nData Scientist Salary\\n1-2 yrs experience ...        ₹ 15.8L   \n",
       "4  Fractal Analytics\\nData Scientist Salary\\n2-4 ...        ₹ 15.4L   \n",
       "5  Tiger Analytics\\nData Scientist Salary\\n2-4 yr...        ₹ 14.7L   \n",
       "6  Sigmoid Analytics\\nData Scientist Salary\\n1 yr...        ₹ 14.7L   \n",
       "7  Legato Health Technologies\\nData Scientist Sal...        ₹ 14.5L   \n",
       "8  HSBC\\nData Scientist Salary\\n4 yrs experience ...        ₹ 14.0L   \n",
       "9  Tredence\\nData Scientist Salary\\n3 yrs experie...        ₹ 13.9L   \n",
       "\n",
       "  Minimum Salary Maximum Salary  \n",
       "0        ₹ 25.0L        ₹ 45.0L  \n",
       "1        ₹ 15.0L        ₹ 26.0L  \n",
       "2        ₹ 11.0L        ₹ 22.6L  \n",
       "3        ₹ 11.0L        ₹ 22.0L  \n",
       "4         ₹ 9.0L        ₹ 23.0L  \n",
       "5         ₹ 9.0L        ₹ 20.0L  \n",
       "6        ₹ 12.7L        ₹ 19.7L  \n",
       "7        ₹ 11.0L        ₹ 20.0L  \n",
       "8        ₹ 12.0L        ₹ 18.0L  \n",
       "9         ₹ 8.8L        ₹ 17.5L  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe\n",
    "lists = [company[0:10],average_salary,min_sal,max_sal]\n",
    "ambition_salary = pd.concat([pd.Series(x) for x in lists], axis=1)\n",
    "ambition_salary.columns=[\"Company\",\"Average Salary\",\"Minimum Salary\",\"Maximum Salary\"]\n",
    "ambition_salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5841c40b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
