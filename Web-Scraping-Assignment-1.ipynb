{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d58e519",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a791168b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in c:\\users\\vaish\\downloads\\original\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\vaish\\downloads\\original\\lib\\site-packages (from bs4) (4.10.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\vaish\\downloads\\original\\lib\\site-packages (from beautifulsoup4->bs4) (2.2.1)\n",
      "Requirement already satisfied: requests in c:\\users\\vaish\\downloads\\original\\lib\\site-packages (2.26.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\vaish\\downloads\\original\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vaish\\downloads\\original\\lib\\site-packages (from requests) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\vaish\\downloads\\original\\lib\\site-packages (from requests) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vaish\\downloads\\original\\lib\\site-packages (from requests) (3.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4\n",
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e26dabfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d6998ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dde3e7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5fe7275e",
   "metadata": {},
   "outputs": [],
   "source": [
    "page=requests.get(\"https://www.wikipedia.org/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "91fe9feb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ee3986f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d777e3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "html=urlopen('https://en.wikipedia.org/wiki/Main_Page')\n",
    "bs=BeautifulSoup(html,\"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "df2f0bef",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of all the header tags :\n",
      "\n",
      "<h1 class=\"firstHeading mw-first-heading\" id=\"firstHeading\" style=\"display: none\"><span class=\"mw-page-title-main\">Main Page</span></h1>\n",
      "\n",
      "<h1><span class=\"mw-headline\" id=\"Welcome_to_Wikipedia\">Welcome to <a href=\"/wiki/Wikipedia\" title=\"Wikipedia\">Wikipedia</a></span></h1>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-tfa-h2\"><span id=\"From_today.27s_featured_article\"></span><span class=\"mw-headline\" id=\"From_today's_featured_article\">From today's featured article</span></h2>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-dyk-h2\"><span class=\"mw-headline\" id=\"Did_you_know_...\">Did you know ...</span></h2>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-itn-h2\"><span class=\"mw-headline\" id=\"In_the_news\">In the news</span></h2>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-otd-h2\"><span class=\"mw-headline\" id=\"On_this_day\">On this day</span></h2>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-tfp-h2\"><span id=\"Today.27s_featured_picture\"></span><span class=\"mw-headline\" id=\"Today's_featured_picture\">Today's featured picture</span></h2>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-other\"><span class=\"mw-headline\" id=\"Other_areas_of_Wikipedia\">Other areas of Wikipedia</span></h2>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-sister\"><span id=\"Wikipedia.27s_sister_projects\"></span><span class=\"mw-headline\" id=\"Wikipedia's_sister_projects\">Wikipedia's sister projects</span></h2>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-lang\"><span class=\"mw-headline\" id=\"Wikipedia_languages\">Wikipedia languages</span></h2>\n",
      "\n",
      "<h2>Navigation menu</h2>\n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-personal-label\">\n",
      "<span class=\"vector-menu-heading-label\">Personal tools</span>\n",
      "</h3>\n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-namespaces-label\">\n",
      "<span class=\"vector-menu-heading-label\">Namespaces</span>\n",
      "</h3>\n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-views-label\">\n",
      "<span class=\"vector-menu-heading-label\">Views</span>\n",
      "</h3>\n",
      "\n",
      "<h3>\n",
      "<label for=\"searchInput\">Search</label>\n",
      "</h3>\n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-navigation-label\">\n",
      "<span class=\"vector-menu-heading-label\">Navigation</span>\n",
      "</h3>\n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-interaction-label\">\n",
      "<span class=\"vector-menu-heading-label\">Contribute</span>\n",
      "</h3>\n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-tb-label\">\n",
      "<span class=\"vector-menu-heading-label\">Tools</span>\n",
      "</h3>\n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-coll-print_export-label\">\n",
      "<span class=\"vector-menu-heading-label\">Print/export</span>\n",
      "</h3>\n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-wikibase-otherprojects-label\">\n",
      "<span class=\"vector-menu-heading-label\">In other projects</span>\n",
      "</h3>\n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-lang-label\">\n",
      "<span class=\"vector-menu-heading-label\">Languages</span>\n",
      "</h3>\n"
     ]
    }
   ],
   "source": [
    "titles = bs.find_all(['h1', 'h2','h3','h4','h5','h6'])\n",
    "print('List of all the header tags :', *titles, sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1637e854",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c60c9db3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie Name</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Year of Release</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.\\nThe Shawshank Redemption\\n(1994)</td>\n",
       "      <td>9.3</td>\n",
       "      <td>(1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.\\nThe Godfather\\n(1972)</td>\n",
       "      <td>9.2</td>\n",
       "      <td>(1972)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.\\nThe Dark Knight\\n(2008)</td>\n",
       "      <td>9.0</td>\n",
       "      <td>(2008)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.\\nThe Lord of the Rings: The Return of the K...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>(2003)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.\\nSchindler's List\\n(1993)</td>\n",
       "      <td>9.0</td>\n",
       "      <td>(1993)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.\\nThe Godfather Part II\\n(1974)</td>\n",
       "      <td>9.0</td>\n",
       "      <td>(1974)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.\\n12 Angry Men\\n(1957)</td>\n",
       "      <td>9.0</td>\n",
       "      <td>(1957)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.\\nPulp Fiction\\n(1994)</td>\n",
       "      <td>8.9</td>\n",
       "      <td>(1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.\\nInception\\n(2010)</td>\n",
       "      <td>8.8</td>\n",
       "      <td>(2010)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.\\nThe Lord of the Rings: The Two Towers\\n(2...</td>\n",
       "      <td>8.8</td>\n",
       "      <td>(2002)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.\\nFight Club\\n(1999)</td>\n",
       "      <td>8.8</td>\n",
       "      <td>(1999)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.\\nThe Lord of the Rings: The Fellowship of ...</td>\n",
       "      <td>8.8</td>\n",
       "      <td>(2001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.\\nForrest Gump\\n(1994)</td>\n",
       "      <td>8.8</td>\n",
       "      <td>(1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.\\nIl buono, il brutto, il cattivo\\n(1966)</td>\n",
       "      <td>8.8</td>\n",
       "      <td>(1966)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.\\nThe Matrix\\n(1999)</td>\n",
       "      <td>8.7</td>\n",
       "      <td>(1999)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.\\nGoodfellas\\n(1990)</td>\n",
       "      <td>8.7</td>\n",
       "      <td>(1990)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.\\nThe Empire Strikes Back\\n(1980)</td>\n",
       "      <td>8.7</td>\n",
       "      <td>(1980)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.\\nOne Flew Over the Cuckoo's Nest\\n(1975)</td>\n",
       "      <td>8.7</td>\n",
       "      <td>(1975)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.\\nInterstellar\\n(2014)</td>\n",
       "      <td>8.6</td>\n",
       "      <td>(2014)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.\\nCidade de Deus\\n(2002)</td>\n",
       "      <td>8.6</td>\n",
       "      <td>(2002)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.\\nSen to Chihiro no kamikakushi\\n(2001)</td>\n",
       "      <td>8.6</td>\n",
       "      <td>(2001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.\\nSaving Private Ryan\\n(1998)</td>\n",
       "      <td>8.6</td>\n",
       "      <td>(1998)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.\\nThe Green Mile\\n(1999)</td>\n",
       "      <td>8.6</td>\n",
       "      <td>(1999)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.\\nLa vita è bella\\n(1997)</td>\n",
       "      <td>8.6</td>\n",
       "      <td>(1997)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.\\nSe7en\\n(1995)</td>\n",
       "      <td>8.6</td>\n",
       "      <td>(1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.\\nTerminator 2: Judgment Day\\n(1991)</td>\n",
       "      <td>8.6</td>\n",
       "      <td>(1991)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.\\nThe Silence of the Lambs\\n(1991)</td>\n",
       "      <td>8.6</td>\n",
       "      <td>(1991)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.\\nStar Wars\\n(1977)</td>\n",
       "      <td>8.6</td>\n",
       "      <td>(1977)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.\\nSeppuku\\n(1962)</td>\n",
       "      <td>8.6</td>\n",
       "      <td>(1962)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.\\nShichinin no samurai\\n(1954)</td>\n",
       "      <td>8.6</td>\n",
       "      <td>(1954)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31.\\nIt's a Wonderful Life\\n(1946)</td>\n",
       "      <td>8.6</td>\n",
       "      <td>(1946)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32.\\nGisaengchung\\n(2019)</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(2019)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33.\\nWhiplash\\n(2014)</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(2014)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34.\\nTop Gun: Maverick\\n(2022)</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(2022)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35.\\nThe Intouchables\\n(2011)</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(2011)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36.\\nThe Prestige\\n(2006)</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(2006)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37.\\nThe Departed\\n(2006)</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(2006)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38.\\nThe Pianist\\n(2002)</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(2002)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39.\\nGladiator\\n(2000)</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(2000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40.\\nAmerican History X\\n(1998)</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(1998)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>41.\\nThe Usual Suspects\\n(1995)</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>42.\\nLéon\\n(1994)</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>43.\\nThe Lion King\\n(1994)</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>44.\\nNuovo Cinema Paradiso\\n(1988)</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(1988)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>45.\\nHotaru no haka\\n(1988)</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(1988)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>46.\\nBack to the Future\\n(1985)</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(1985)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>47.\\nApocalypse Now\\n(1979)</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(1979)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>48.\\nAlien\\n(1979)</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(1979)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49.\\nOnce Upon a Time in the West\\n(1968)</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(1968)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>50.\\nPsycho\\n(1960)</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(1960)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Movie Name Rating Year of Release\n",
       "0                1.\\nThe Shawshank Redemption\\n(1994)    9.3          (1994)\n",
       "1                           2.\\nThe Godfather\\n(1972)    9.2          (1972)\n",
       "2                         3.\\nThe Dark Knight\\n(2008)    9.0          (2008)\n",
       "3   4.\\nThe Lord of the Rings: The Return of the K...    9.0          (2003)\n",
       "4                        5.\\nSchindler's List\\n(1993)    9.0          (1993)\n",
       "5                   6.\\nThe Godfather Part II\\n(1974)    9.0          (1974)\n",
       "6                            7.\\n12 Angry Men\\n(1957)    9.0          (1957)\n",
       "7                            8.\\nPulp Fiction\\n(1994)    8.9          (1994)\n",
       "8                               9.\\nInception\\n(2010)    8.8          (2010)\n",
       "9   10.\\nThe Lord of the Rings: The Two Towers\\n(2...    8.8          (2002)\n",
       "10                            11.\\nFight Club\\n(1999)    8.8          (1999)\n",
       "11  12.\\nThe Lord of the Rings: The Fellowship of ...    8.8          (2001)\n",
       "12                          13.\\nForrest Gump\\n(1994)    8.8          (1994)\n",
       "13       14.\\nIl buono, il brutto, il cattivo\\n(1966)    8.8          (1966)\n",
       "14                            15.\\nThe Matrix\\n(1999)    8.7          (1999)\n",
       "15                            16.\\nGoodfellas\\n(1990)    8.7          (1990)\n",
       "16               17.\\nThe Empire Strikes Back\\n(1980)    8.7          (1980)\n",
       "17       18.\\nOne Flew Over the Cuckoo's Nest\\n(1975)    8.7          (1975)\n",
       "18                          19.\\nInterstellar\\n(2014)    8.6          (2014)\n",
       "19                        20.\\nCidade de Deus\\n(2002)    8.6          (2002)\n",
       "20         21.\\nSen to Chihiro no kamikakushi\\n(2001)    8.6          (2001)\n",
       "21                   22.\\nSaving Private Ryan\\n(1998)    8.6          (1998)\n",
       "22                        23.\\nThe Green Mile\\n(1999)    8.6          (1999)\n",
       "23                       24.\\nLa vita è bella\\n(1997)    8.6          (1997)\n",
       "24                                 25.\\nSe7en\\n(1995)    8.6          (1995)\n",
       "25            26.\\nTerminator 2: Judgment Day\\n(1991)    8.6          (1991)\n",
       "26              27.\\nThe Silence of the Lambs\\n(1991)    8.6          (1991)\n",
       "27                             28.\\nStar Wars\\n(1977)    8.6          (1977)\n",
       "28                               29.\\nSeppuku\\n(1962)    8.6          (1962)\n",
       "29                  30.\\nShichinin no samurai\\n(1954)    8.6          (1954)\n",
       "30                 31.\\nIt's a Wonderful Life\\n(1946)    8.6          (1946)\n",
       "31                          32.\\nGisaengchung\\n(2019)    8.5          (2019)\n",
       "32                              33.\\nWhiplash\\n(2014)    8.5          (2014)\n",
       "33                     34.\\nTop Gun: Maverick\\n(2022)    8.5          (2022)\n",
       "34                      35.\\nThe Intouchables\\n(2011)    8.5          (2011)\n",
       "35                          36.\\nThe Prestige\\n(2006)    8.5          (2006)\n",
       "36                          37.\\nThe Departed\\n(2006)    8.5          (2006)\n",
       "37                           38.\\nThe Pianist\\n(2002)    8.5          (2002)\n",
       "38                             39.\\nGladiator\\n(2000)    8.5          (2000)\n",
       "39                    40.\\nAmerican History X\\n(1998)    8.5          (1998)\n",
       "40                    41.\\nThe Usual Suspects\\n(1995)    8.5          (1995)\n",
       "41                                  42.\\nLéon\\n(1994)    8.5          (1994)\n",
       "42                         43.\\nThe Lion King\\n(1994)    8.5          (1994)\n",
       "43                 44.\\nNuovo Cinema Paradiso\\n(1988)    8.5          (1988)\n",
       "44                        45.\\nHotaru no haka\\n(1988)    8.5          (1988)\n",
       "45                    46.\\nBack to the Future\\n(1985)    8.5          (1985)\n",
       "46                        47.\\nApocalypse Now\\n(1979)    8.5          (1979)\n",
       "47                                 48.\\nAlien\\n(1979)    8.5          (1979)\n",
       "48          49.\\nOnce Upon a Time in the West\\n(1968)    8.5          (1968)\n",
       "49                                50.\\nPsycho\\n(1960)    8.5          (1960)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url=requests.get(\"https://www.imdb.com/search/title/?groups=top_100&sort=user_rating,desc\")\n",
    "soup=BeautifulSoup(url.content,\"html.parser\")\n",
    "\n",
    "#Scraping Movie Name\n",
    "name=soup.find_all(\"h3\",class_=\"lister-item-header\")\n",
    "\n",
    "a=[]\n",
    "for i in range(0,len(name)):\n",
    "    a.append(name[i].text)\n",
    "    \n",
    "a=list(map(lambda x:x.strip(),a))\n",
    "\n",
    "\n",
    "#Scraping Rating\n",
    "rate=soup.find_all(\"div\",class_=\"inline-block ratings-imdb-rating\")\n",
    "b=[]\n",
    "for i2 in range(0,len(rate)):\n",
    "    b.append(rate[i2].text)\n",
    "    \n",
    "b=list(map(lambda x:x.strip(\"\\n\"),b))\n",
    "\n",
    "#Scraping Year of Release\n",
    "year=soup.find_all(\"span\",class_=\"lister-item-year text-muted unbold\")\n",
    "c=[]\n",
    "for i3 in range(0,len(year)):\n",
    "    c.append(year[i3].text)\n",
    "    \n",
    "#creating dataframe\n",
    "lists = [a,b,c]\n",
    "df = pd.concat([pd.Series(x) for x in lists], axis=1)\n",
    "df.columns=[\"Movie Name\",\"Rating\",\"Year of Release\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a459fe0",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d308e84d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie Name</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Year of Release</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.\\n      Rocketry: The Nambi Effect\\n(2022)</td>\n",
       "      <td>[\\n, [8.5], \\n]</td>\n",
       "      <td>(2004)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.\\n      Anbe Sivam\\n(2003)</td>\n",
       "      <td>[\\n, [8.4], \\n]</td>\n",
       "      <td>(2004)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.\\n      Golmaal\\n(1979)</td>\n",
       "      <td>[\\n, [8.4], \\n]</td>\n",
       "      <td>(2004)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.\\n      Nayakan\\n(1987)</td>\n",
       "      <td>[\\n, [8.4], \\n]</td>\n",
       "      <td>(2004)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.\\n      Jai Bhim\\n(2021)</td>\n",
       "      <td>[\\n, [8.4], \\n]</td>\n",
       "      <td>(2004)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96.\\n      Angoor\\n(1982)</td>\n",
       "      <td>[\\n, [8.0], \\n]</td>\n",
       "      <td>(2004)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97.\\n      Rang De Basanti\\n(2006)</td>\n",
       "      <td>[\\n, [8.0], \\n]</td>\n",
       "      <td>(2004)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98.\\n      Baahubali 2: The Conclusion\\n(2017)</td>\n",
       "      <td>[\\n, [8.0], \\n]</td>\n",
       "      <td>(2004)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99.\\n      Baasha\\n(1995)</td>\n",
       "      <td>[\\n, [8.0], \\n]</td>\n",
       "      <td>(2004)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100.\\n      Virumandi\\n(2004)</td>\n",
       "      <td>[\\n, [8.0], \\n]</td>\n",
       "      <td>(2004)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Movie Name           Rating  \\\n",
       "0     1.\\n      Rocketry: The Nambi Effect\\n(2022)  [\\n, [8.5], \\n]   \n",
       "1                     2.\\n      Anbe Sivam\\n(2003)  [\\n, [8.4], \\n]   \n",
       "2                        3.\\n      Golmaal\\n(1979)  [\\n, [8.4], \\n]   \n",
       "3                        4.\\n      Nayakan\\n(1987)  [\\n, [8.4], \\n]   \n",
       "4                       5.\\n      Jai Bhim\\n(2021)  [\\n, [8.4], \\n]   \n",
       "..                                             ...              ...   \n",
       "95                       96.\\n      Angoor\\n(1982)  [\\n, [8.0], \\n]   \n",
       "96              97.\\n      Rang De Basanti\\n(2006)  [\\n, [8.0], \\n]   \n",
       "97  98.\\n      Baahubali 2: The Conclusion\\n(2017)  [\\n, [8.0], \\n]   \n",
       "98                       99.\\n      Baasha\\n(1995)  [\\n, [8.0], \\n]   \n",
       "99                   100.\\n      Virumandi\\n(2004)  [\\n, [8.0], \\n]   \n",
       "\n",
       "   Year of Release  \n",
       "0           (2004)  \n",
       "1           (2004)  \n",
       "2           (2004)  \n",
       "3           (2004)  \n",
       "4           (2004)  \n",
       "..             ...  \n",
       "95          (2004)  \n",
       "96          (2004)  \n",
       "97          (2004)  \n",
       "98          (2004)  \n",
       "99          (2004)  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url=requests.get(\"https://www.imdb.com/india/top-rated-indian-movies/\")\n",
    "soup=BeautifulSoup(url.content,\"html.parser\")\n",
    "import pandas as pd\n",
    "\n",
    "#Scraping Movie Name\n",
    "name=soup.find_all(\"td\",class_=\"titleColumn\")\n",
    "a=[]\n",
    "for i in range(0,100):\n",
    "    a.append(name[i].text)\n",
    "    \n",
    "a=list(map(lambda x:x.strip(),a))\n",
    "\n",
    "#Scraping Rating\n",
    "rate=soup.find_all(\"td\",class_=\"ratingColumn imdbRating\")\n",
    "rate=rate[0:100]            \n",
    "\n",
    "\n",
    "#Scraping Year of Release\n",
    "year=soup.find_all(\"span\",class_=\"secondaryInfo\")\n",
    "y=[]\n",
    "for i3 in range(0,100):\n",
    "    y.append(year[i].text)\n",
    "\n",
    "#creating dataframe\n",
    "lists = [a,rate,y]\n",
    "df = pd.concat([pd.Series(x) for x in lists], axis=1)\n",
    "df.columns=[\"Movie Name\",\"Rating\",\"Year of Release\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef6bc59",
   "metadata": {},
   "source": [
    "# Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "265f80d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>The list of respected former presidents of India</th>\n",
       "      <th>Term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shri Ram Nath Kovind (birth - 1945)</td>\n",
       "      <td>Term of Office: 25 July, 2017 to 25 July, 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shri Pranab Mukherjee (1935-2020)</td>\n",
       "      <td>Term of Office: 25 July, 2012 to 25 July, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Smt Pratibha Devisingh Patil (birth - 1934)</td>\n",
       "      <td>Term of Office: 25 July, 2007 to 25 July, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DR. A.P.J. Abdul Kalam (1931-2015)</td>\n",
       "      <td>Term of Office: 25 July, 2002 to 25 July, 2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shri K. R. Narayanan (1920 - 2005)</td>\n",
       "      <td>Term of Office: 25 July, 1997 to 25 July, 2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dr Shankar Dayal Sharma (1918-1999)</td>\n",
       "      <td>Term of Office: 25 July, 1992 to 25 July, 1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Shri R Venkataraman (1910-2009)</td>\n",
       "      <td>Term of Office: 25 July, 1987 to 25 July, 1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Giani Zail Singh (1916-1994)</td>\n",
       "      <td>Term of Office: 25 July, 1982 to 25 July, 1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Shri Neelam Sanjiva Reddy (1913-1996)</td>\n",
       "      <td>Term of Office: 25 July, 1977 to 25 July, 1982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dr. Fakhruddin Ali Ahmed (1905-1977)</td>\n",
       "      <td>Term of Office: 24 August, 1974 to 11 February...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Shri Varahagiri Venkata Giri (1894-1980)</td>\n",
       "      <td>Term of Office: 3 May, 1969 to 20 July, 1969 a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Dr. Zakir Husain (1897-1969)</td>\n",
       "      <td>Term of Office: 13 May, 1967 to 3 May, 1969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Dr. Sarvepalli Radhakrishnan (1888-1975)</td>\n",
       "      <td>Term of Office: 13 May, 1962 to 13 May, 1967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Dr. Rajendra Prasad (1884-1963)</td>\n",
       "      <td>Term of Office: 26 January, 1950 to 13 May, 1962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   The list of respected former presidents of India  \\\n",
       "0               Shri Ram Nath Kovind (birth - 1945)   \n",
       "1                 Shri Pranab Mukherjee (1935-2020)   \n",
       "2       Smt Pratibha Devisingh Patil (birth - 1934)   \n",
       "3                DR. A.P.J. Abdul Kalam (1931-2015)   \n",
       "4                Shri K. R. Narayanan (1920 - 2005)   \n",
       "5               Dr Shankar Dayal Sharma (1918-1999)   \n",
       "6                   Shri R Venkataraman (1910-2009)   \n",
       "7                      Giani Zail Singh (1916-1994)   \n",
       "8             Shri Neelam Sanjiva Reddy (1913-1996)   \n",
       "9              Dr. Fakhruddin Ali Ahmed (1905-1977)   \n",
       "10         Shri Varahagiri Venkata Giri (1894-1980)   \n",
       "11                     Dr. Zakir Husain (1897-1969)   \n",
       "12         Dr. Sarvepalli Radhakrishnan (1888-1975)   \n",
       "13                 Dr. Rajendra Prasad (1884-1963)    \n",
       "\n",
       "                                                 Term  \n",
       "0     Term of Office: 25 July, 2017 to 25 July, 2022   \n",
       "1     Term of Office: 25 July, 2012 to 25 July, 2017   \n",
       "2     Term of Office: 25 July, 2007 to 25 July, 2012   \n",
       "3     Term of Office: 25 July, 2002 to 25 July, 2007   \n",
       "4     Term of Office: 25 July, 1997 to 25 July, 2002   \n",
       "5     Term of Office: 25 July, 1992 to 25 July, 1997   \n",
       "6     Term of Office: 25 July, 1987 to 25 July, 1992   \n",
       "7     Term of Office: 25 July, 1982 to 25 July, 1987   \n",
       "8     Term of Office: 25 July, 1977 to 25 July, 1982   \n",
       "9   Term of Office: 24 August, 1974 to 11 February...  \n",
       "10  Term of Office: 3 May, 1969 to 20 July, 1969 a...  \n",
       "11        Term of Office: 13 May, 1967 to 3 May, 1969  \n",
       "12       Term of Office: 13 May, 1962 to 13 May, 1967  \n",
       "13   Term of Office: 26 January, 1950 to 13 May, 1962  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "data=requests.get(\"https://presidentofindia.nic.in/former-presidents.htm\")\n",
    "bs = BeautifulSoup(data.text, \"html.parser\")\n",
    "\n",
    "#Scraping President's Names\n",
    "name=[bs.find_all(\"div\",class_=\"presidentListing\")]\n",
    "name1=bs.find_all(\"h3\")\n",
    "\n",
    "n1=[]\n",
    "for i in range(0,len(name1)):\n",
    "    n1.append(name1[i].text)\n",
    "\n",
    "#print(\"The list of respected former presidents of India\", n1)\n",
    "\n",
    "#Scraping Terms of Presidents\n",
    "\n",
    "t=[bs.find_all(\"div\",class_=\"presidentListing\")]\n",
    "b=[]\n",
    "for i1 in t:\n",
    "    b=bs.find_all(\"p\")\n",
    "\n",
    "b1=b[0:7:2]\n",
    "b2=b[8:18]\n",
    "\n",
    "for i2 in b2 :\n",
    "    b1.append(i2)\n",
    "\n",
    "term=[]\n",
    "for i3 in range(0,len(b1)):\n",
    "    term.append(b1[i3].text)\n",
    "    \n",
    "#creating dataframe\n",
    "lists = [n1,term]\n",
    "df = pd.concat([pd.Series(x) for x in lists], axis=1)\n",
    "df.columns=[\"The list of respected former presidents of India\",\"Term\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f4dcb4",
   "metadata": {},
   "source": [
    "# Question 5(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cfddcbaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teams</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>19</td>\n",
       "      <td>2,355</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>England</td>\n",
       "      <td>27</td>\n",
       "      <td>3,226</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>India</td>\n",
       "      <td>31</td>\n",
       "      <td>3,447</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>22</td>\n",
       "      <td>2,354</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Australia</td>\n",
       "      <td>25</td>\n",
       "      <td>2,548</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>21</td>\n",
       "      <td>2,111</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>30</td>\n",
       "      <td>2,753</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>29</td>\n",
       "      <td>2,658</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>41</td>\n",
       "      <td>2,902</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>18</td>\n",
       "      <td>1,238</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Ireland</td>\n",
       "      <td>23</td>\n",
       "      <td>1,214</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Scotland</td>\n",
       "      <td>27</td>\n",
       "      <td>1,254</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>25</td>\n",
       "      <td>973</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Netherlands</td>\n",
       "      <td>21</td>\n",
       "      <td>673</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>UAE</td>\n",
       "      <td>22</td>\n",
       "      <td>697</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>United States</td>\n",
       "      <td>23</td>\n",
       "      <td>725</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Oman</td>\n",
       "      <td>30</td>\n",
       "      <td>919</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Namibia</td>\n",
       "      <td>15</td>\n",
       "      <td>369</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Nepal</td>\n",
       "      <td>22</td>\n",
       "      <td>331</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Papua New Guinea</td>\n",
       "      <td>22</td>\n",
       "      <td>134</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Teams Matches Points Ratings\n",
       "0        New Zealand      19  2,355     124\n",
       "1            England      27  3,226     119\n",
       "2              India      31  3,447     111\n",
       "3           Pakistan      22  2,354     107\n",
       "4          Australia      25  2,548     102\n",
       "5       South Africa      21  2,111     101\n",
       "6         Bangladesh      30  2,753      92\n",
       "7          Sri Lanka      29  2,658      92\n",
       "8        West Indies      41  2,902      71\n",
       "9        Afghanistan      18  1,238      69\n",
       "10           Ireland      23  1,214      53\n",
       "11          Scotland      27  1,254      46\n",
       "12          Zimbabwe      25    973      39\n",
       "13       Netherlands      21    673      32\n",
       "14               UAE      22    697      32\n",
       "15     United States      23    725      32\n",
       "16              Oman      30    919      31\n",
       "17           Namibia      15    369      25\n",
       "18             Nepal      22    331      15\n",
       "19  Papua New Guinea      22    134       6"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "x1=requests.get(\"https://www.icc-cricket.com/rankings/mens/team-rankings/odi\")\n",
    "soup=BeautifulSoup(x1.text,\"html.parser\")\n",
    "\n",
    "#Scraping Team Names\n",
    "x1=soup.find_all(\"span\",class_=\"u-hide-phablet\")\n",
    "x2=[]\n",
    "for i in range(0,len(x1)):\n",
    "    x2.append(x1[i].text)\n",
    "    \n",
    "#print(\"Top 10 ODI teams in men’s cricket :\\n\", x2)\n",
    "\n",
    "\n",
    "#Scraping Matches\n",
    "m1=soup.find(\"td\",class_=\"rankings-block__banner--matches\")\n",
    "m2=soup.find_all(\"td\",class_=\"table-body__cell u-center-text\")\n",
    "m3=[]\n",
    "for i in range(0,len(m2)):\n",
    "    m3.append(m2[i].text)\n",
    "    \n",
    "p2=m3[1::2]    \n",
    "matches=m3[0::2]\n",
    "matches.insert(0,(m1.text))\n",
    "\n",
    "#print(\"Top 10 ODI Men's Team matches: \\n\", matches)\n",
    "\n",
    "#Scraping Points\n",
    "p1=soup.find(\"td\", class_=\"rankings-block__banner--points\")\n",
    "p2.insert(0,(p1.text))\n",
    "#print(\"Top 10 ODI Men's Team points: \\n\", p2)\n",
    "\n",
    "#Scraping Ratings\n",
    "r1=soup.find(\"td\",class_=\"rankings-block__banner--rating u-text-right\")\n",
    "r2=soup.find_all(\"td\",class_=\"table-body__cell u-text-right rating\")\n",
    "r3=[]\n",
    "for i in range(0,len(r2)):\n",
    "    r3.append(r2[i].text)\n",
    "\n",
    "r3.insert(0,(r1.text.strip(\"      \\n          \")))\n",
    "#print(\"Top 10 ODI Men's Team ratings:\\n\",r3)\n",
    "\n",
    "#creating dataframe\n",
    "lists = [x2,matches,p2,r3]\n",
    "df = pd.concat([pd.Series(x) for x in lists], axis=1)\n",
    "df.columns=[\"Teams\",\"Matches\",\"Points\",\"Ratings\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495782c6",
   "metadata": {},
   "source": [
    "# Question 5(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "17661154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Babar Azam</td>\n",
       "      <td>\\n\\nPAK\\n</td>\n",
       "      <td>789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rassie van der Dussen</td>\n",
       "      <td>SA</td>\n",
       "      <td>784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Quinton de Kock</td>\n",
       "      <td>SA</td>\n",
       "      <td>779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Imam-ul-Haq</td>\n",
       "      <td>PAK</td>\n",
       "      <td>744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>IND</td>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Charles Amini</td>\n",
       "      <td>PNG</td>\n",
       "      <td>436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Matthew Cross</td>\n",
       "      <td>SCO</td>\n",
       "      <td>433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Chundangapoyil Rizwan</td>\n",
       "      <td>UAE</td>\n",
       "      <td>425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Chirag Suri</td>\n",
       "      <td>UAE</td>\n",
       "      <td>424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Philip Salt</td>\n",
       "      <td>ENG</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Player       Team Ratings\n",
       "0              Babar Azam  \\n\\nPAK\\n     789\n",
       "1   Rassie van der Dussen         SA     784\n",
       "2         Quinton de Kock         SA     779\n",
       "3             Imam-ul-Haq        PAK     744\n",
       "4             Virat Kohli        IND     740\n",
       "..                    ...        ...     ...\n",
       "95          Charles Amini        PNG     436\n",
       "96          Matthew Cross        SCO     433\n",
       "97  Chundangapoyil Rizwan        UAE     425\n",
       "98            Chirag Suri        UAE     424\n",
       "99            Philip Salt        ENG     NaN\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url=requests.get(\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting\")\n",
    "soup=BeautifulSoup(url.content,\"html.parser\")\n",
    "\n",
    "#Scraping Player name\n",
    "pl1=soup.find(\"div\",class_=\"rankings-block__banner--name-large\").text\n",
    "pl2=soup.find_all(\"td\",class_=\"table-body__cell rankings-table__name name\")\n",
    "pl3=[]\n",
    "for i in range(0,len(pl2)):\n",
    "    pl3.append((pl2[i].text).strip(\"\\n\"))\n",
    "    \n",
    "pl3.insert(0,pl1)\n",
    "#print(\"Top 10 ODI Batsmen\", pl3)\n",
    "\n",
    "#Scraping Team\n",
    "t1=soup.find(\"div\",class_=\"rankings-block__banner--nationality\")\n",
    "team1=soup.find_all(\"span\",class_=\"table-body__logo-text\")\n",
    "x=[]\n",
    "for i in range(0,len(team1)):\n",
    "    x.append(team1[i].text)\n",
    "    \n",
    "x.insert(0,(t1.text))\n",
    "#print(\"Top 10 ODI Batsmen Teams\", x)\n",
    "\n",
    "\n",
    "#Scraping Rating\n",
    "r1=soup.find(\"div\",class_=\"rankings-block__banner--rating\").text\n",
    "r2=soup.find_all(\"td\",class_=\"table-body__cell rating\")\n",
    "r3=[]\n",
    "for i3 in range(0,len(r2)):\n",
    "    r3.append(r2[i3].text)\n",
    "    \n",
    "#print(\"Top 10 ODI Batsmen Rating\", r3)\n",
    "#creating dataframe\n",
    "lists = [pl3,x,r3]\n",
    "df = pd.concat([pd.Series(x) for x in lists], axis=1)\n",
    "df.columns=[\"Player\",\"Team\",\"Ratings\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15148c4",
   "metadata": {},
   "source": [
    "# Question 5c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "03ac8237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trent Boult</td>\n",
       "      <td>NZ</td>\n",
       "      <td>720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Josh Hazlewood</td>\n",
       "      <td>AUS</td>\n",
       "      <td>678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mujeeb Ur Rahman</td>\n",
       "      <td>AFG</td>\n",
       "      <td>676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jasprit Bumrah</td>\n",
       "      <td>IND</td>\n",
       "      <td>662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shaheen Afridi</td>\n",
       "      <td>PAK</td>\n",
       "      <td>661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Mark Adair</td>\n",
       "      <td>IRE</td>\n",
       "      <td>390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Sompal Kami</td>\n",
       "      <td>NEP</td>\n",
       "      <td>390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Karan KC</td>\n",
       "      <td>NEP</td>\n",
       "      <td>387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Norman Vanua</td>\n",
       "      <td>PNG</td>\n",
       "      <td>386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Wayne Parnell</td>\n",
       "      <td>SA</td>\n",
       "      <td>380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Player Team Ratings\n",
       "0        Trent Boult   NZ     720\n",
       "1     Josh Hazlewood  AUS     678\n",
       "2   Mujeeb Ur Rahman  AFG     676\n",
       "3     Jasprit Bumrah  IND     662\n",
       "4     Shaheen Afridi  PAK     661\n",
       "..               ...  ...     ...\n",
       "95        Mark Adair  IRE     390\n",
       "96       Sompal Kami  NEP     390\n",
       "97          Karan KC  NEP     387\n",
       "98      Norman Vanua  PNG     386\n",
       "99     Wayne Parnell   SA     380\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url=requests.get(\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling\")\n",
    "soup=BeautifulSoup(url.content,\"html.parser\")\n",
    "\n",
    "#Scraping bowlers names\n",
    "n1=soup.find(\"div\",class_=\"rankings-block__banner--name-large\")\n",
    "n2=soup.find_all(\"td\",class_=\"table-body__cell rankings-table__name name\")\n",
    "a=[]\n",
    "for i in range(0,len(n2)):\n",
    "    a.append(n2[i].text)\n",
    "    \n",
    "a=list(map(lambda x:x.strip(),a))\n",
    "\n",
    "a.insert(0,(n1.text))\n",
    "#print(\"Top 10 ODI bowlers\",a)\n",
    "    \n",
    "\n",
    "#Scraping Teams\n",
    "\n",
    "t1=(soup.find(\"div\",class_=\"rankings-block__banner--nationality\")).text\n",
    "t2=soup.find_all(\"span\",class_=\"table-body__logo-text\")\n",
    "b=[]\n",
    "for i in range(0,len(t2)):\n",
    "    b.append((t2[i].text))\n",
    "    \n",
    "b.insert(0,(t1.strip(\"\\n\")))\n",
    "#print(\"Top 10 ODI bowler's Teams\",b)\n",
    "\n",
    "#Scraping Ratings\n",
    "\n",
    "r1=soup.find(\"div\",class_='rankings-block__banner--rating')\n",
    "r2=soup.find_all(\"td\",class_=\"table-body__cell rating\")\n",
    "c=[]\n",
    "for i in range(0,len(r2)):\n",
    "    c.append(r2[i].text)\n",
    "\n",
    "c.insert(0,(r1.text))\n",
    "#print(\"Top 10 ODI bowler's Ratings\",c)\n",
    "\n",
    "#creating dataframe\n",
    "lists = [a,b,c]\n",
    "df = pd.concat([pd.Series(x) for x in lists], axis=1)\n",
    "df.columns=[\"Player\",\"Team\",\"Ratings\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f0a3f3",
   "metadata": {},
   "source": [
    "# Question 6a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2c1bc123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teams</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>33</td>\n",
       "      <td>4,046</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>England</td>\n",
       "      <td>35</td>\n",
       "      <td>4,157</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>32</td>\n",
       "      <td>3,219</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India</td>\n",
       "      <td>31</td>\n",
       "      <td>3,019</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>30</td>\n",
       "      <td>2,768</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>12</td>\n",
       "      <td>930</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>30</td>\n",
       "      <td>1,962</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>11</td>\n",
       "      <td>516</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ireland</td>\n",
       "      <td>11</td>\n",
       "      <td>495</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Teams Matches Points Ratings\n",
       "0      Australia      33  4,046     167\n",
       "1        England      35  4,157     123\n",
       "2   South Africa      32  3,219     119\n",
       "3          India      31  3,019     101\n",
       "4    New Zealand      30  2,768      97\n",
       "5    West Indies      12    930      92\n",
       "6     Bangladesh      30  1,962      78\n",
       "7       Pakistan      11    516      65\n",
       "8        Ireland      11    495      47\n",
       "9      Sri Lanka       8      0      45\n",
       "10      Zimbabwe     NaN    NaN       0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url=requests.get(\"https://www.icc-cricket.com/rankings/womens/team-rankings/odi\")\n",
    "soup=BeautifulSoup(url.content,\"html.parser\")\n",
    "\n",
    "#Scraping Teams\n",
    "t=soup.find_all(\"span\",class_=\"u-hide-phablet\")\n",
    "b=[]\n",
    "for i1 in range(0,len(t)):\n",
    "    b.append(t[i1].text)\n",
    "\n",
    "#print(\"Top 10 ODI teams in women’s cricket:\\n\",b)\n",
    "\n",
    "#Scraping Matches and Points\n",
    "x=soup.find_all(\"td\", class_=\"table-body__cell u-center-text\")\n",
    "a=[]\n",
    "for i in range(0,len(x)):\n",
    "    a.append(x[i].text)\n",
    "\n",
    "matches=a[0::2]\n",
    "points=a[1::2]\n",
    "#print(\"Top 10 ODI Team's matches:\\n\",matches)\n",
    "#print(\"Top 10 ODI Team's points:\\n\",points)\n",
    "\n",
    "#Scraping Rating\n",
    "y=soup.find_all(\"td\", class_=\"table-body__cell u-text-right rating\")\n",
    "c=[]\n",
    "for i2 in range(0,len(y)):\n",
    "    c.append(y[i2].text)\n",
    "\n",
    "    \n",
    "y1=soup.find_all(\"td\", class_=\"rankings-block__banner--rating u-text-right\")\n",
    "d=[]\n",
    "for i3 in range(0,len(y1)):\n",
    "    d.append(y1[i3].text)\n",
    "\n",
    "#removing \\n from the list\n",
    "d=list(map(lambda x:x.strip(),d))\n",
    "\n",
    "\n",
    "c.insert(0,d[0])\n",
    "\n",
    "#print(\"Top 10 ODI Team's ratings:\\n\",c)\n",
    "#creating dataframe\n",
    "lists = [b,matches,points,c]\n",
    "df = pd.concat([pd.Series(x) for x in lists], axis=1)\n",
    "df.columns=[\"Teams\",\"Matches\",\"Points\",\"Ratings\"]\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd382180",
   "metadata": {},
   "source": [
    "# Question 6b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ab751743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Teams</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alyssa Healy</td>\n",
       "      <td>AUS</td>\n",
       "      <td>785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beth Mooney</td>\n",
       "      <td>AUS</td>\n",
       "      <td>749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Laura Wolvaardt</td>\n",
       "      <td>SA</td>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Meg Lanning</td>\n",
       "      <td>AUS</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Sneh Rana</td>\n",
       "      <td>IND</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Frederique Overdijk</td>\n",
       "      <td>NED</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Sabbhineni Meghana</td>\n",
       "      <td>IND</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Anushka Sanjeewani</td>\n",
       "      <td>SL</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Meghna Singh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Player Teams Ratings\n",
       "0          Alyssa Healy   AUS     785\n",
       "1           Beth Mooney   AUS     749\n",
       "2        Natalie Sciver   ENG     747\n",
       "3       Laura Wolvaardt    SA     732\n",
       "4           Meg Lanning   AUS     710\n",
       "..                  ...   ...     ...\n",
       "95            Sneh Rana   IND     212\n",
       "96  Frederique Overdijk   NED     210\n",
       "97   Sabbhineni Meghana   IND     210\n",
       "98   Anushka Sanjeewani    SL     209\n",
       "99         Meghna Singh   NaN     NaN\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url1=requests.get(\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting\")\n",
    "\n",
    "soup1=BeautifulSoup(url1.content,\"html.parser\")\n",
    "\n",
    "#Scraping Players\n",
    "player1=(soup1.find(\"div\",class_=\"rankings-block__banner--name-large\")).text\n",
    "player2=soup1.find_all(\"td\", class_=\"table-body__cell rankings-table__name name\")\n",
    "\n",
    "\n",
    "p2=[]\n",
    "for i in range(0,len(player2)):\n",
    "    p2.append(player2[i].text)\n",
    "    \n",
    " #removing \\n from the list   \n",
    "p2=list(map(lambda x:x.strip(),p2))\n",
    "\n",
    "p2.insert(0,player1)\n",
    "#print(\"Top 10 women’s ODI Batting players\", p2)\n",
    "\n",
    "#Scraping Team\n",
    "team1=soup1.find(\"div\",class_=\"rankings-block__banner--nationality\")\n",
    "\n",
    "team2=soup1.find_all(\"span\",class_=\"table-body__logo-text\")\n",
    "a=[]\n",
    "for i in range(0,len(team2)-1):\n",
    "    a.append(team2[i].text)\n",
    "\n",
    "a.insert(0,(team1.text.strip(\"\\n\")))\n",
    "#print(\"Top 10 women’s ODI Batting player's teams\", a)\n",
    "\n",
    "\n",
    "#Scraping Rating\n",
    "rate1=soup1.find(\"div\", class_=\"rankings-block__banner--rating\")\n",
    "\n",
    "rate2=soup1.find_all(\"td\",class_=\"table-body__cell rating\")\n",
    "b=[]\n",
    "for i in range(0, len(rate2)-1):\n",
    "    b.append(rate2[i].text)\n",
    "\n",
    "b.insert(0,(rate1.text))\n",
    "#print(\"Top 10 women’s ODI Batting player's ratings\", b)\n",
    "#creating dataframe\n",
    "lists = [p2,a,b]\n",
    "df = pd.concat([pd.Series(x) for x in lists], axis=1)\n",
    "df.columns=[\"Player\",\"Teams\",\"Ratings\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea442da4",
   "metadata": {},
   "source": [
    "# Question 6c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ef92ba4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Teams</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Marizanne Kapp</td>\n",
       "      <td>SA</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hayley Matthews</td>\n",
       "      <td>WI</td>\n",
       "      <td>339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amelia Kerr</td>\n",
       "      <td>NZ</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ashleigh Gardner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Deepti Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jess Jonassen</td>\n",
       "      <td>AUS</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Katherine Brunt</td>\n",
       "      <td>ENG</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Stafanie Taylor</td>\n",
       "      <td>WI</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Jhulan Goswami</td>\n",
       "      <td>IND</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Sophie Ecclestone</td>\n",
       "      <td>ENG</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Sophie Devine</td>\n",
       "      <td>NZ</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Rumana Ahmed</td>\n",
       "      <td>BAN</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Nida Dar</td>\n",
       "      <td>PAK</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Chloe-Lesleigh Tryon</td>\n",
       "      <td>SA</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Salma Khatun</td>\n",
       "      <td>BAN</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Chamari Athapaththu</td>\n",
       "      <td>SL</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Sune Luus</td>\n",
       "      <td>SA</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Harmanpreet Kaur</td>\n",
       "      <td>IND</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Player Teams Ratings\n",
       "0         Natalie Sciver   ENG     379\n",
       "1           Ellyse Perry   AUS     374\n",
       "2         Marizanne Kapp    SA     349\n",
       "3        Hayley Matthews    WI     339\n",
       "4            Amelia Kerr    NZ     336\n",
       "5       Ashleigh Gardner   AUS     270\n",
       "6          Deepti Sharma   IND     252\n",
       "7          Jess Jonassen   AUS     246\n",
       "8        Katherine Brunt   ENG     220\n",
       "9        Stafanie Taylor    WI     207\n",
       "10        Jhulan Goswami   IND     205\n",
       "11     Sophie Ecclestone   ENG     202\n",
       "12         Sophie Devine    NZ     202\n",
       "13          Rumana Ahmed   BAN     201\n",
       "14              Nida Dar   PAK     200\n",
       "15  Chloe-Lesleigh Tryon    SA     197\n",
       "16          Salma Khatun   BAN     178\n",
       "17   Chamari Athapaththu    SL     178\n",
       "18             Sune Luus    SA     171\n",
       "19      Harmanpreet Kaur   IND     158"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url=requests.get(\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder\")\n",
    "soup=BeautifulSoup(url.content,\"html.parser\")\n",
    "\n",
    "#Scraping player name\n",
    "name1=soup.find(\"div\",class_=\"rankings-block__banner--name-large\")\n",
    "name2=soup.find_all(\"td\",class_=\"table-body__cell rankings-table__name name\")\n",
    "\n",
    "\n",
    "n1=[]\n",
    "for i in range(0,len(name2)):\n",
    "    n1.append(name2[i].text)\n",
    "\n",
    "n1=list(map(lambda x:x.strip(),n1))\n",
    "n1.insert(0,(name1.text))\n",
    "#print(\"Top 10 women’s ODI all-rounder\",n1)\n",
    "\n",
    "\n",
    "#Scraping Team\n",
    "team1=soup.find(\"div\",class_=\"rankings-block__banner--nationality\")\n",
    "\n",
    "team2=soup.find_all(\"span\",class_=\"table-body__logo-text\")\n",
    "t2=[]\n",
    "for i in range(0,len(team2)):\n",
    "    t2.append(team2[i].text)\n",
    "\n",
    "t2.insert(0,(team1.text.strip(\"\\n\")))\n",
    "#print(\"Top 10 women’s ODI all-rounder teams\",t2)\n",
    "\n",
    "#Scraping Rating\n",
    "rate1=soup.find(\"div\",class_=\"rankings-block__banner--rating\")\n",
    "rate2=soup.find_all(\"td\",class_=\"table-body__cell rating\")\n",
    "\n",
    "r1=[]\n",
    "for i in range(0,len(rate2)):\n",
    "    r1.append(rate2[i].text)\n",
    "\n",
    "r1.insert(0,(rate1.text))\n",
    "#print(\"Top 10 women’s ODI all-rounder ratings\",r1)\n",
    "\n",
    "#creating dataframe\n",
    "lists = [n1,t2,r1]\n",
    "df = pd.concat([pd.Series(x) for x in lists], axis=1)\n",
    "df.columns=[\"Player\",\"Teams\",\"Ratings\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5151ad",
   "metadata": {},
   "source": [
    "# Question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c533d168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headline:\t ['EU economics chief says bloc is not afraid of Putin, ready to react over halted Russian gas supplies']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time Stamp</th>\n",
       "      <th>News Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 Hour Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/03/europe-ready-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/03/eu-urges-china...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/02/trump-pick-in-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/02/how-quiet-quit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/02/pro-picks-watc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/02/comcast-execut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/02/investing-club...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>16 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/02/as-wall-street...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/02/john-podesta-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/02/trump-ex-attor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/02/million-dollar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>16 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/02/chobani-pulls-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>17 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/02/these-were-the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>17 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/02/pga-tour-denie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>17 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/02/august-jobs-re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>18 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/02/why-divorced-o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/02/investing-club...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/02/low-vol-etfs-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/02/fox-news-perso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/02/gm-offers-to-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>19 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/02/virtual-realit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>19 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/02/august-jobs-re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>19 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/02/stocks-making-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>19 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/02/-omicron-covid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>19 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/02/honor-launches...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>19 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/02/1970s-inflatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>19 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/02/nyc-sues-starb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>20 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/02/white-house-sl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>20 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/02/student-loan-f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>20 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/02/crypto-winter-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.cnbc.com/2022/09/03/europe-ready-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.cnbc.com/2022/09/03/eu-urges-china...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.cnbc.com/2022/09/02/trump-pick-in-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.cnbc.com/2022/09/02/how-quiet-quit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.cnbc.com/2022/09/02/pro-picks-watc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.cnbc.com/2022/09/02/comcast-execut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.cnbc.com/2022/09/02/investing-club...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.cnbc.com/2022/09/02/as-wall-street...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.cnbc.com/2022/09/02/john-podesta-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.cnbc.com/2022/09/02/trump-ex-attor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.cnbc.com/2022/09/02/million-dollar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.cnbc.com/2022/09/02/chobani-pulls-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.cnbc.com/2022/09/02/these-were-the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.cnbc.com/2022/09/02/pga-tour-denie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.cnbc.com/2022/09/02/august-jobs-re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.cnbc.com/2022/09/02/why-divorced-o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.cnbc.com/2022/09/02/investing-club...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.cnbc.com/2022/09/02/low-vol-etfs-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.cnbc.com/2022/09/02/fox-news-perso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.cnbc.com/2022/09/02/gm-offers-to-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.cnbc.com/2022/09/02/virtual-realit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.cnbc.com/2022/09/02/august-jobs-re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.cnbc.com/2022/09/02/stocks-making-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.cnbc.com/2022/09/02/-omicron-covid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.cnbc.com/2022/09/02/honor-launches...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.cnbc.com/2022/09/02/1970s-inflatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.cnbc.com/2022/09/02/nyc-sues-starb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.cnbc.com/2022/09/02/white-house-sl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.cnbc.com/2022/09/02/student-loan-f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.cnbc.com/2022/09/02/crypto-winter-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Time Stamp                                          News Link\n",
       "0     1 Hour Ago  https://www.cnbc.com/2022/09/03/europe-ready-t...\n",
       "1    2 Hours Ago  https://www.cnbc.com/2022/09/03/eu-urges-china...\n",
       "2   14 Hours Ago  https://www.cnbc.com/2022/09/02/trump-pick-in-...\n",
       "3   14 Hours Ago  https://www.cnbc.com/2022/09/02/how-quiet-quit...\n",
       "4   14 Hours Ago  https://www.cnbc.com/2022/09/02/pro-picks-watc...\n",
       "5   15 Hours Ago  https://www.cnbc.com/2022/09/02/comcast-execut...\n",
       "6   15 Hours Ago  https://www.cnbc.com/2022/09/02/investing-club...\n",
       "7   16 Hours Ago  https://www.cnbc.com/2022/09/02/as-wall-street...\n",
       "8   16 Hours Ago  https://www.cnbc.com/2022/09/02/john-podesta-t...\n",
       "9   16 Hours Ago  https://www.cnbc.com/2022/09/02/trump-ex-attor...\n",
       "10  16 Hours Ago  https://www.cnbc.com/2022/09/02/million-dollar...\n",
       "11  16 Hours Ago  https://www.cnbc.com/2022/09/02/chobani-pulls-...\n",
       "12  17 Hours Ago  https://www.cnbc.com/2022/09/02/these-were-the...\n",
       "13  17 Hours Ago  https://www.cnbc.com/2022/09/02/pga-tour-denie...\n",
       "14  17 Hours Ago  https://www.cnbc.com/2022/09/02/august-jobs-re...\n",
       "15  18 Hours Ago  https://www.cnbc.com/2022/09/02/why-divorced-o...\n",
       "16  18 Hours Ago  https://www.cnbc.com/2022/09/02/investing-club...\n",
       "17  18 Hours Ago  https://www.cnbc.com/2022/09/02/low-vol-etfs-a...\n",
       "18  19 Hours Ago  https://www.cnbc.com/2022/09/02/fox-news-perso...\n",
       "19  19 Hours Ago  https://www.cnbc.com/2022/09/02/gm-offers-to-b...\n",
       "20  19 Hours Ago  https://www.cnbc.com/2022/09/02/virtual-realit...\n",
       "21  19 Hours Ago  https://www.cnbc.com/2022/09/02/august-jobs-re...\n",
       "22  19 Hours Ago  https://www.cnbc.com/2022/09/02/stocks-making-...\n",
       "23  19 Hours Ago  https://www.cnbc.com/2022/09/02/-omicron-covid...\n",
       "24  19 Hours Ago  https://www.cnbc.com/2022/09/02/honor-launches...\n",
       "25  19 Hours Ago  https://www.cnbc.com/2022/09/02/1970s-inflatio...\n",
       "26  19 Hours Ago  https://www.cnbc.com/2022/09/02/nyc-sues-starb...\n",
       "27  20 Hours Ago  https://www.cnbc.com/2022/09/02/white-house-sl...\n",
       "28  20 Hours Ago  https://www.cnbc.com/2022/09/02/student-loan-f...\n",
       "29  20 Hours Ago  https://www.cnbc.com/2022/09/02/crypto-winter-...\n",
       "30           NaN  https://www.cnbc.com/2022/09/03/europe-ready-t...\n",
       "31           NaN  https://www.cnbc.com/2022/09/03/eu-urges-china...\n",
       "32           NaN  https://www.cnbc.com/2022/09/02/trump-pick-in-...\n",
       "33           NaN  https://www.cnbc.com/2022/09/02/how-quiet-quit...\n",
       "34           NaN  https://www.cnbc.com/2022/09/02/pro-picks-watc...\n",
       "35           NaN  https://www.cnbc.com/2022/09/02/comcast-execut...\n",
       "36           NaN  https://www.cnbc.com/2022/09/02/investing-club...\n",
       "37           NaN  https://www.cnbc.com/2022/09/02/as-wall-street...\n",
       "38           NaN  https://www.cnbc.com/2022/09/02/john-podesta-t...\n",
       "39           NaN  https://www.cnbc.com/2022/09/02/trump-ex-attor...\n",
       "40           NaN  https://www.cnbc.com/2022/09/02/million-dollar...\n",
       "41           NaN  https://www.cnbc.com/2022/09/02/chobani-pulls-...\n",
       "42           NaN  https://www.cnbc.com/2022/09/02/these-were-the...\n",
       "43           NaN  https://www.cnbc.com/2022/09/02/pga-tour-denie...\n",
       "44           NaN  https://www.cnbc.com/2022/09/02/august-jobs-re...\n",
       "45           NaN  https://www.cnbc.com/2022/09/02/why-divorced-o...\n",
       "46           NaN  https://www.cnbc.com/2022/09/02/investing-club...\n",
       "47           NaN  https://www.cnbc.com/2022/09/02/low-vol-etfs-a...\n",
       "48           NaN  https://www.cnbc.com/2022/09/02/fox-news-perso...\n",
       "49           NaN  https://www.cnbc.com/2022/09/02/gm-offers-to-b...\n",
       "50           NaN  https://www.cnbc.com/2022/09/02/virtual-realit...\n",
       "51           NaN  https://www.cnbc.com/2022/09/02/august-jobs-re...\n",
       "52           NaN  https://www.cnbc.com/2022/09/02/stocks-making-...\n",
       "53           NaN  https://www.cnbc.com/2022/09/02/-omicron-covid...\n",
       "54           NaN  https://www.cnbc.com/2022/09/02/honor-launches...\n",
       "55           NaN  https://www.cnbc.com/2022/09/02/1970s-inflatio...\n",
       "56           NaN  https://www.cnbc.com/2022/09/02/nyc-sues-starb...\n",
       "57           NaN  https://www.cnbc.com/2022/09/02/white-house-sl...\n",
       "58           NaN  https://www.cnbc.com/2022/09/02/student-loan-f...\n",
       "59           NaN  https://www.cnbc.com/2022/09/02/crypto-winter-..."
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "x=requests.get(\"https://www.cnbc.com/world/?region=world\")\n",
    "\n",
    "soup=BeautifulSoup(x.content,\"html.parser\")\n",
    "\n",
    "#Headlines Scraping\n",
    "head=soup.find_all(\"div\",class_=\"FeaturedCard-contentText\")\n",
    "\n",
    "a=[]\n",
    "for i in range(0,len(head)):\n",
    "    a.append((head[i].text))\n",
    "\n",
    "print(\"Headline:\\t\", a)\n",
    "\n",
    "#Time Scraping\n",
    "time=soup.find_all(\"time\",class_=\"LatestNews-timestamp\")\n",
    "\n",
    "b=[]\n",
    "for i2 in range(0,len(time)):\n",
    "    b.append((time[i2].text))\n",
    "\n",
    "#print(\"Time:\\t\", b)\n",
    "\n",
    "#News Link Scraping\n",
    "link=soup.find_all(\"a\",class_=\"LatestNews-headline\")\n",
    "\n",
    "for i in link:\n",
    "    lk.append(i[\"href\"])\n",
    "    \n",
    "    \n",
    "#creating dataframe\n",
    "lists = [b,lk]\n",
    "df = pd.concat([pd.Series(x) for x in lists], axis=1)\n",
    "df.columns=[\"Time Stamp\",\"News Link\"]\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a70906",
   "metadata": {},
   "source": [
    "# Question 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dff2a832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Published Date</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reward is enough</td>\n",
       "      <td>Silver, David, Singh, Satinder, Precup, Doina,...</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Making sense of raw input</td>\n",
       "      <td>Evans, Richard, Bošnjak, Matko and 5 more</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Law and logic: A review from an argumentation ...</td>\n",
       "      <td>Prakken, Henry, Sartor, Giovanni</td>\n",
       "      <td>October 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Creativity and artificial intelligence</td>\n",
       "      <td>Boden, Margaret A.</td>\n",
       "      <td>August 1998</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Artificial cognition for social human–robot in...</td>\n",
       "      <td>Lemaignan, Séverin, Warnier, Mathieu and 3 more</td>\n",
       "      <td>June 2017</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Explanation in artificial intelligence: Insigh...</td>\n",
       "      <td>Miller, Tim</td>\n",
       "      <td>February 2019</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Making sense of sensory input</td>\n",
       "      <td>Evans, Richard, Hernández-Orallo, José and 3 more</td>\n",
       "      <td>April 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Conflict-based search for optimal multi-agent ...</td>\n",
       "      <td>Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...</td>\n",
       "      <td>February 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Between MDPs and semi-MDPs: A framework for te...</td>\n",
       "      <td>Sutton, Richard S., Precup, Doina, Singh, Sati...</td>\n",
       "      <td>August 1999</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Hanabi challenge: A new frontier for AI re...</td>\n",
       "      <td>Bard, Nolan, Foerster, Jakob N. and 13 more</td>\n",
       "      <td>March 2020</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Evaluating XAI: A comparison of rule-based and...</td>\n",
       "      <td>van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...</td>\n",
       "      <td>February 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Argumentation in artificial intelligence</td>\n",
       "      <td>Bench-Capon, T.J.M., Dunne, Paul E.</td>\n",
       "      <td>October 2007</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Algorithms for computing strategies in two-pla...</td>\n",
       "      <td>Bošanský, Branislav, Lisý, Viliam and 3 more</td>\n",
       "      <td>August 2016</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Multiple object tracking: A literature review</td>\n",
       "      <td>Luo, Wenhan, Xing, Junliang and 4 more</td>\n",
       "      <td>April 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Selection of relevant features and examples in...</td>\n",
       "      <td>Blum, Avrim L., Langley, Pat</td>\n",
       "      <td>December 1997</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A survey of inverse reinforcement learning: Ch...</td>\n",
       "      <td>Arora, Saurabh, Doshi, Prashant</td>\n",
       "      <td>August 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Explaining individual predictions when feature...</td>\n",
       "      <td>Aas, Kjersti, Jullum, Martin, Løland, Anders</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>A review of possible effects of cognitive bias...</td>\n",
       "      <td>Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...</td>\n",
       "      <td>June 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Integrating social power into the decision-mak...</td>\n",
       "      <td>Pereira, Gonçalo, Prada, Rui, Santos, Pedro A.</td>\n",
       "      <td>December 2016</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>“That's (not) the output I expected!” On the r...</td>\n",
       "      <td>Riveiro, Maria, Thill, Serge</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Explaining black-box classifiers using post-ho...</td>\n",
       "      <td>Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...</td>\n",
       "      <td>May 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Algorithm runtime prediction: Methods &amp; evalua...</td>\n",
       "      <td>Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...</td>\n",
       "      <td>January 2014</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Wrappers for feature subset selection</td>\n",
       "      <td>Kohavi, Ron, John, George H.</td>\n",
       "      <td>December 1997</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Commonsense visual sensemaking for autonomous ...</td>\n",
       "      <td>Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Quantum computation, quantum theory and AI</td>\n",
       "      <td>Ying, Mingsheng</td>\n",
       "      <td>February 2010</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title  \\\n",
       "0                                    Reward is enough   \n",
       "1                           Making sense of raw input   \n",
       "2   Law and logic: A review from an argumentation ...   \n",
       "3              Creativity and artificial intelligence   \n",
       "4   Artificial cognition for social human–robot in...   \n",
       "5   Explanation in artificial intelligence: Insigh...   \n",
       "6                       Making sense of sensory input   \n",
       "7   Conflict-based search for optimal multi-agent ...   \n",
       "8   Between MDPs and semi-MDPs: A framework for te...   \n",
       "9   The Hanabi challenge: A new frontier for AI re...   \n",
       "10  Evaluating XAI: A comparison of rule-based and...   \n",
       "11           Argumentation in artificial intelligence   \n",
       "12  Algorithms for computing strategies in two-pla...   \n",
       "13      Multiple object tracking: A literature review   \n",
       "14  Selection of relevant features and examples in...   \n",
       "15  A survey of inverse reinforcement learning: Ch...   \n",
       "16  Explaining individual predictions when feature...   \n",
       "17  A review of possible effects of cognitive bias...   \n",
       "18  Integrating social power into the decision-mak...   \n",
       "19  “That's (not) the output I expected!” On the r...   \n",
       "20  Explaining black-box classifiers using post-ho...   \n",
       "21  Algorithm runtime prediction: Methods & evalua...   \n",
       "22              Wrappers for feature subset selection   \n",
       "23  Commonsense visual sensemaking for autonomous ...   \n",
       "24         Quantum computation, quantum theory and AI   \n",
       "\n",
       "                                               Author  Published Date  \\\n",
       "0   Silver, David, Singh, Satinder, Precup, Doina,...    October 2021   \n",
       "1           Evans, Richard, Bošnjak, Matko and 5 more    October 2021   \n",
       "2                   Prakken, Henry, Sartor, Giovanni     October 2015   \n",
       "3                                 Boden, Margaret A.      August 1998   \n",
       "4     Lemaignan, Séverin, Warnier, Mathieu and 3 more       June 2017   \n",
       "5                                        Miller, Tim    February 2019   \n",
       "6   Evans, Richard, Hernández-Orallo, José and 3 more      April 2021   \n",
       "7   Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...   February 2015   \n",
       "8   Sutton, Richard S., Precup, Doina, Singh, Sati...     August 1999   \n",
       "9         Bard, Nolan, Foerster, Jakob N. and 13 more      March 2020   \n",
       "10  van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...   February 2021   \n",
       "11               Bench-Capon, T.J.M., Dunne, Paul E.     October 2007   \n",
       "12       Bošanský, Branislav, Lisý, Viliam and 3 more     August 2016   \n",
       "13             Luo, Wenhan, Xing, Junliang and 4 more      April 2021   \n",
       "14                      Blum, Avrim L., Langley, Pat    December 1997   \n",
       "15                   Arora, Saurabh, Doshi, Prashant      August 2021   \n",
       "16      Aas, Kjersti, Jullum, Martin, Løland, Anders   September 2021   \n",
       "17  Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...       June 2021   \n",
       "18    Pereira, Gonçalo, Prada, Rui, Santos, Pedro A.    December 2016   \n",
       "19                      Riveiro, Maria, Thill, Serge   September 2021   \n",
       "20  Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...        May 2021   \n",
       "21  Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...    January 2014   \n",
       "22                      Kohavi, Ron, John, George H.    December 1997   \n",
       "23  Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...    October 2021   \n",
       "24                                   Ying, Mingsheng    February 2010   \n",
       "\n",
       "                                                  URL  \n",
       "0   https://www.sciencedirect.com/science/article/...  \n",
       "1   https://www.sciencedirect.com/science/article/...  \n",
       "2   https://www.sciencedirect.com/science/article/...  \n",
       "3   https://www.sciencedirect.com/science/article/...  \n",
       "4   https://www.sciencedirect.com/science/article/...  \n",
       "5   https://www.sciencedirect.com/science/article/...  \n",
       "6   https://www.sciencedirect.com/science/article/...  \n",
       "7   https://www.sciencedirect.com/science/article/...  \n",
       "8   https://www.sciencedirect.com/science/article/...  \n",
       "9   https://www.sciencedirect.com/science/article/...  \n",
       "10  https://www.sciencedirect.com/science/article/...  \n",
       "11  https://www.sciencedirect.com/science/article/...  \n",
       "12  https://www.sciencedirect.com/science/article/...  \n",
       "13  https://www.sciencedirect.com/science/article/...  \n",
       "14  https://www.sciencedirect.com/science/article/...  \n",
       "15  https://www.sciencedirect.com/science/article/...  \n",
       "16  https://www.sciencedirect.com/science/article/...  \n",
       "17  https://www.sciencedirect.com/science/article/...  \n",
       "18  https://www.sciencedirect.com/science/article/...  \n",
       "19  https://www.sciencedirect.com/science/article/...  \n",
       "20  https://www.sciencedirect.com/science/article/...  \n",
       "21  https://www.sciencedirect.com/science/article/...  \n",
       "22  https://www.sciencedirect.com/science/article/...  \n",
       "23  https://www.sciencedirect.com/science/article/...  \n",
       "24  https://www.sciencedirect.com/science/article/...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "data=requests.get(\"https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\")\n",
    "bs=BeautifulSoup(data.text,'html.parser')\n",
    "\n",
    "# Paper title scraping\n",
    "record=bs.find_all(\"h2\",class_=\"sc-1qrq3sd-1 MKjKb sc-1nmom32-0 sc-1nmom32-1 hqhUYH ebTA-dR\")\n",
    "a=[]\n",
    "for i in range(0,len(record)):\n",
    "    a.append(record[i].text)\n",
    "\n",
    "#print(\"The Paper titles are : \\t\", a )\n",
    "\n",
    "#Authors Scraping\n",
    "\n",
    "author=bs.find_all(\"span\",class_=\"sc-1w3fpd7-0 pgLAT\")\n",
    "b=[]\n",
    "for i2 in range(0,len(author)):\n",
    "    b.append(author[i2].text)\n",
    "    \n",
    "#print(\"The Authors are : \\t\", b)  \n",
    "\n",
    "#Published Date Scraping\n",
    "\n",
    "date=bs.find_all(\"span\",class_=\"sc-1thf9ly-2 bKddwo\")\n",
    "c=[]\n",
    "for i3 in range(0,len(date)):\n",
    "    c.append(date[i3].text)\n",
    "    \n",
    "#print(\"The Published Dates are : \\t\", c)  \n",
    "\n",
    "\n",
    "#Paper URL Scraping\n",
    "\n",
    "url=bs.find_all(\"a\",class_=\"sc-5smygv-0 nrDZj\")\n",
    "lk=[]\n",
    "for i4 in url:\n",
    "    lk.append(i4[\"href\"])\n",
    "    \n",
    "#creating dataframe\n",
    "lists = [a,b,c,lk]\n",
    "df = pd.concat([pd.Series(x) for x in lists], axis=1)\n",
    "df.columns=[\"Title\",\"Author\",\"Published Date\",\"URL\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8a7b33",
   "metadata": {},
   "source": [
    "# Question 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "17f2e2f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant Name</th>\n",
       "      <th>Cuisine</th>\n",
       "      <th>Location</th>\n",
       "      <th>Rating</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tamasha</td>\n",
       "      <td>₹ 2,000 for 2 (approx) | Continental, Asian, I...</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.2</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Local</td>\n",
       "      <td>₹ 2,000 for 2 (approx) | North Indian, Asian, ...</td>\n",
       "      <td>Scindia House,Connaught Place, Central Delhi</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Openhouse Cafe</td>\n",
       "      <td>₹ 2,000 for 2 (approx) | North Indian, Asian, ...</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ministry Of Beer</td>\n",
       "      <td>₹ 3,000 for 2 (approx) | North Indian, Contine...</td>\n",
       "      <td>M-Block,Connaught Place, Central Delhi</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Station Bar</td>\n",
       "      <td>₹ 1,100 for 2 (approx) | Italian, Chinese, Nor...</td>\n",
       "      <td>F-Block,Connaught Place, Central Delhi</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>QBA</td>\n",
       "      <td>₹ 2,100 for 2 (approx) | North Indian, Contine...</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Junkyard Cafe</td>\n",
       "      <td>₹ 2,100 for 2 (approx) | North Indian, Contine...</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The G.T. ROAD</td>\n",
       "      <td>₹ 1,400 for 2 (approx) | North Indian</td>\n",
       "      <td>M-Block,Connaught Place, Central Delhi</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Connaught Clubhouse Microbrewery</td>\n",
       "      <td>₹ 1,800 for 2 (approx) | North Indian, Contine...</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Berco's</td>\n",
       "      <td>₹ 1,300 for 2 (approx) | Chinese, Thai</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Chido</td>\n",
       "      <td>₹ 1,800 for 2 (approx) | North Indian, Italian...</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.2</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>My Bar Headquarters</td>\n",
       "      <td>₹ 1,500 for 2 (approx) | North Indian, Chinese</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Farzi Cafe</td>\n",
       "      <td>₹ 2,000 for 2 (approx) | Modern Indian, Contin...</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Unplugged Courtyard</td>\n",
       "      <td>₹ 3,300 for 2 (approx) | North Indian, Italian...</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>38 Barracks</td>\n",
       "      <td>₹ 2,700 for 2 (approx) | North Indian, Chinese...</td>\n",
       "      <td>M-Block,Connaught Place, Central Delhi</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Ardor 2.1 Restaurant and Lounge</td>\n",
       "      <td>₹ 2,000 for 2 (approx) | North Indian, Chinese...</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>3.8</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Out Of The Box Courtyard</td>\n",
       "      <td>₹ 2,200 for 2 (approx) | North Indian, Mediter...</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Sandoz</td>\n",
       "      <td>₹ 1,400 for 2 (approx) | North Indian, Chinese...</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>The Luggage Room By Sandoz</td>\n",
       "      <td>₹ 1,600 for 2 (approx) | Chinese, Italian, Nor...</td>\n",
       "      <td>M-Block,Connaught Place, Central Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Chili's American Grill and Bar</td>\n",
       "      <td>₹ 2,000 for 2 (approx) | Mexican, American, Te...</td>\n",
       "      <td>M-Block,Connaught Place, Central Delhi</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>₹ 2,500 for 2 (approx) | Asian, Finger Food, C...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Restaurant Name  \\\n",
       "0                            Tamasha   \n",
       "1                              Local   \n",
       "2                     Openhouse Cafe   \n",
       "3                   Ministry Of Beer   \n",
       "4                        Station Bar   \n",
       "5                                QBA   \n",
       "6                  The Junkyard Cafe   \n",
       "7                      The G.T. ROAD   \n",
       "8   Connaught Clubhouse Microbrewery   \n",
       "9                            Berco's   \n",
       "10                             Chido   \n",
       "11               My Bar Headquarters   \n",
       "12                        Farzi Cafe   \n",
       "13               Unplugged Courtyard   \n",
       "14                       38 Barracks   \n",
       "15   Ardor 2.1 Restaurant and Lounge   \n",
       "16          Out Of The Box Courtyard   \n",
       "17                            Sandoz   \n",
       "18        The Luggage Room By Sandoz   \n",
       "19    Chili's American Grill and Bar   \n",
       "20                               NaN   \n",
       "\n",
       "                                              Cuisine  \\\n",
       "0   ₹ 2,000 for 2 (approx) | Continental, Asian, I...   \n",
       "1   ₹ 2,000 for 2 (approx) | North Indian, Asian, ...   \n",
       "2   ₹ 2,000 for 2 (approx) | North Indian, Asian, ...   \n",
       "3   ₹ 3,000 for 2 (approx) | North Indian, Contine...   \n",
       "4   ₹ 1,100 for 2 (approx) | Italian, Chinese, Nor...   \n",
       "5   ₹ 2,100 for 2 (approx) | North Indian, Contine...   \n",
       "6   ₹ 2,100 for 2 (approx) | North Indian, Contine...   \n",
       "7               ₹ 1,400 for 2 (approx) | North Indian   \n",
       "8   ₹ 1,800 for 2 (approx) | North Indian, Contine...   \n",
       "9              ₹ 1,300 for 2 (approx) | Chinese, Thai   \n",
       "10  ₹ 1,800 for 2 (approx) | North Indian, Italian...   \n",
       "11     ₹ 1,500 for 2 (approx) | North Indian, Chinese   \n",
       "12  ₹ 2,000 for 2 (approx) | Modern Indian, Contin...   \n",
       "13  ₹ 3,300 for 2 (approx) | North Indian, Italian...   \n",
       "14  ₹ 2,700 for 2 (approx) | North Indian, Chinese...   \n",
       "15  ₹ 2,000 for 2 (approx) | North Indian, Chinese...   \n",
       "16  ₹ 2,200 for 2 (approx) | North Indian, Mediter...   \n",
       "17  ₹ 1,400 for 2 (approx) | North Indian, Chinese...   \n",
       "18  ₹ 1,600 for 2 (approx) | Chinese, Italian, Nor...   \n",
       "19  ₹ 2,000 for 2 (approx) | Mexican, American, Te...   \n",
       "20  ₹ 2,500 for 2 (approx) | Asian, Finger Food, C...   \n",
       "\n",
       "                                        Location Rating  \\\n",
       "0                 Connaught Place, Central Delhi    4.2   \n",
       "1   Scindia House,Connaught Place, Central Delhi      4   \n",
       "2                 Connaught Place, Central Delhi    4.1   \n",
       "3         M-Block,Connaught Place, Central Delhi      4   \n",
       "4         F-Block,Connaught Place, Central Delhi    4.1   \n",
       "5                 Connaught Place, Central Delhi    4.3   \n",
       "6                 Connaught Place, Central Delhi    4.1   \n",
       "7         M-Block,Connaught Place, Central Delhi    4.3   \n",
       "8                 Connaught Place, Central Delhi    4.3   \n",
       "9                 Connaught Place, Central Delhi    4.3   \n",
       "10                Connaught Place, Central Delhi    4.2   \n",
       "11                Connaught Place, Central Delhi      4   \n",
       "12                Connaught Place, Central Delhi    4.1   \n",
       "13                Connaught Place, Central Delhi      4   \n",
       "14        M-Block,Connaught Place, Central Delhi    4.3   \n",
       "15                Connaught Place, Central Delhi    3.8   \n",
       "16                Connaught Place, Central Delhi    4.1   \n",
       "17                Connaught Place, Central Delhi      4   \n",
       "18        M-Block,Connaught Place, Central Delhi    3.9   \n",
       "19        M-Block,Connaught Place, Central Delhi    4.3   \n",
       "20                                           NaN    NaN   \n",
       "\n",
       "                                                  URL  \n",
       "0   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "1   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "2   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "3   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "4   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "5   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "6   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "7   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "8   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "9   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "10  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "11  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "12  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "13  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "14  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "15  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "16  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "17  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "18  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "19  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "20  https://im1.dineout.co.in/images/uploads/resta...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "data=requests.get(\"https://www.dineout.co.in/delhi-restaurants/welcome-back\")\n",
    "soup=BeautifulSoup(data.content,\"html.parser\")\n",
    "\n",
    "x=soup.find(\"div\",class_=\"restnt-card-wrap-new\").find_all(\"div\")\n",
    "\n",
    "#restaurant name\n",
    "name=soup.find_all(\"a\",class_=\"restnt-name ellipsis\")\n",
    "a=[]\n",
    "for i in range(0,len(name)-1):\n",
    "    a.append(name[i].text)\n",
    "#print(\"Restaurant names\", a)\n",
    "\n",
    "#restaurant cuisine\n",
    "\n",
    "w=soup.find_all(\"span\",class_=\"double-line-ellipsis\")\n",
    "temp=[]\n",
    "for i in range(0,len(w)):\n",
    "    temp.append(w[i].text)\n",
    "    \n",
    "#print(\"Restaurant Cuisine\", temp)\n",
    "\n",
    "#restaurant location\n",
    "location=soup.find_all(\"div\",class_=\"restnt-loc ellipsis\")\n",
    "b=[]\n",
    "for i2 in range(0,len(name)-1):\n",
    "    b.append(location[i2].text)\n",
    "#print(\"Restaurant Location\", b)\n",
    "\n",
    "#restaurant rating\n",
    "rating=soup.find_all(\"div\",class_=\"restnt-rating rating-4\")\n",
    "c=[]\n",
    "for i3 in range(0,len(name)-1):\n",
    "    c.append(rating[i3].text)\n",
    "    \n",
    "#print(\"Restaurant Rating\", c)\n",
    "\n",
    "#restaurant image url\n",
    "z=soup.find_all(\"img\", class_=\"no-img\")\n",
    "lk=[]\n",
    "for i3 in z:\n",
    "    lk.append(i3[\"data-src\"])\n",
    "    \n",
    "    \n",
    "#creating dataframe\n",
    "lists = [a,temp,b,c,lk]\n",
    "df = pd.concat([pd.Series(x) for x in lists], axis=1)\n",
    "df.columns=[\"Restaurant Name\",\"Cuisine\",\"Location\",\"Rating\",\"URL\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70884e1",
   "metadata": {},
   "source": [
    "# Question 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1b8dfeee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Publication</th>\n",
       "      <th>h5-index</th>\n",
       "      <th>h5-median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>Nature</td>\n",
       "      <td>444</td>\n",
       "      <td>667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>The New England Journal of Medicine</td>\n",
       "      <td>432</td>\n",
       "      <td>780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>Science</td>\n",
       "      <td>401</td>\n",
       "      <td>614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>IEEE/CVF Conference on Computer Vision and Pat...</td>\n",
       "      <td>389</td>\n",
       "      <td>627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>The Lancet</td>\n",
       "      <td>354</td>\n",
       "      <td>635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96.</td>\n",
       "      <td>Journal of Business Research</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97.</td>\n",
       "      <td>Molecular Cancer</td>\n",
       "      <td>145</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98.</td>\n",
       "      <td>Sensors</td>\n",
       "      <td>145</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99.</td>\n",
       "      <td>Nature Climate Change</td>\n",
       "      <td>144</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100.</td>\n",
       "      <td>IEEE Internet of Things Journal</td>\n",
       "      <td>144</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Rank                                        Publication h5-index h5-median\n",
       "0     1.                                             Nature      444       667\n",
       "1     2.                The New England Journal of Medicine      432       780\n",
       "2     3.                                            Science      401       614\n",
       "3     4.  IEEE/CVF Conference on Computer Vision and Pat...      389       627\n",
       "4     5.                                         The Lancet      354       635\n",
       "..   ...                                                ...      ...       ...\n",
       "95   96.                       Journal of Business Research      145       233\n",
       "96   97.                                   Molecular Cancer      145       209\n",
       "97   98.                                            Sensors      145       201\n",
       "98   99.                              Nature Climate Change      144       228\n",
       "99  100.                    IEEE Internet of Things Journal      144       212\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "data=requests.get(\"https://scholar.google.com/citations?view_op=top_venues&hl=en\")\n",
    "soup=BeautifulSoup(data.content,'html.parser')\n",
    "\n",
    "x=soup.find_all(\"td\",class_=\"gsc_mvt_p\")\n",
    "a=[]\n",
    "\n",
    "for i in range(0,len(x)):\n",
    "    a.append((x[i].text))\n",
    "\n",
    "y=soup.find_all(\"td\",class_=\"gsc_mvt_t\")\n",
    "b=[]\n",
    "\n",
    "for i2 in range(0,len(x)):\n",
    "    b.append((y[i2].text))\n",
    "\n",
    "z=soup.find_all(\"a\",class_=\"gs_ibl gsc_mp_anchor\")\n",
    "c=[]\n",
    "\n",
    "for i3 in range(0,len(x)):\n",
    "    c.append((z[i3].text))\n",
    "\n",
    "w=soup.find_all(\"span\", class_=\"gs_ibl gsc_mp_anchor\")\n",
    "d=[]\n",
    "\n",
    "for i4 in range(0,len(x)):\n",
    "    d.append((w[i4].text))\n",
    "\n",
    "# for i5 in range(0,len(x)):\n",
    "#     print(a[i5],b[i5],c[i5],d[i5])\n",
    "\n",
    "#creating dataframe\n",
    "lists = [a,b,c,d]\n",
    "df = pd.concat([pd.Series(x) for x in lists], axis=1)\n",
    "df.columns=[\"Rank\",\"Publication\",\"h5-index\",\"h5-median\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5c7f1ef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['667',\n",
       " '780',\n",
       " '614',\n",
       " '627',\n",
       " '635',\n",
       " '418',\n",
       " '428',\n",
       " '505',\n",
       " '533',\n",
       " '436',\n",
       " '425',\n",
       " '444',\n",
       " '364',\n",
       " '332',\n",
       " '386',\n",
       " '344',\n",
       " '415',\n",
       " '550',\n",
       " '421',\n",
       " '389',\n",
       " '324',\n",
       " '311',\n",
       " '300',\n",
       " '315',\n",
       " '277',\n",
       " '273',\n",
       " '280',\n",
       " '294',\n",
       " '274',\n",
       " '329',\n",
       " '290',\n",
       " '303',\n",
       " '278',\n",
       " '294',\n",
       " '276',\n",
       " '246',\n",
       " '297',\n",
       " '307',\n",
       " '301',\n",
       " '321',\n",
       " '253',\n",
       " '265',\n",
       " '224',\n",
       " '296',\n",
       " '220',\n",
       " '223',\n",
       " '315',\n",
       " '296',\n",
       " '228',\n",
       " '217',\n",
       " '232',\n",
       " '314',\n",
       " '304',\n",
       " '234',\n",
       " '254',\n",
       " '296',\n",
       " '293',\n",
       " '243',\n",
       " '229',\n",
       " '231',\n",
       " '207',\n",
       " '302',\n",
       " '265',\n",
       " '264',\n",
       " '220',\n",
       " '248',\n",
       " '263',\n",
       " '220',\n",
       " '304',\n",
       " '243',\n",
       " '214',\n",
       " '211',\n",
       " '242',\n",
       " '214',\n",
       " '340',\n",
       " '235',\n",
       " '217',\n",
       " '212',\n",
       " '194',\n",
       " '249',\n",
       " '278',\n",
       " '211',\n",
       " '292',\n",
       " '233',\n",
       " '228',\n",
       " '225',\n",
       " '222',\n",
       " '214',\n",
       " '225',\n",
       " '222',\n",
       " '196',\n",
       " '205',\n",
       " '202',\n",
       " '201',\n",
       " '190',\n",
       " '233',\n",
       " '209',\n",
       " '201',\n",
       " '228',\n",
       " '212']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e292b3e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
